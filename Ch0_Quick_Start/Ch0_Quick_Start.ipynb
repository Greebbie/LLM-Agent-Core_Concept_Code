{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93d0aa4a",
   "metadata": {},
   "source": [
    "# Ch0 | æé€Ÿä¸Šæ‰‹ï¼šæé€Ÿæ‰‹æ“ç¥ç»ç½‘ç»œ\n",
    "\n",
    "---\n",
    "\n",
    "**æ ¸å¿ƒç†å¿µï¼š** å¿«é€Ÿäº²è‡ªæ„å»ºç¥ç»ç½‘ç»œ\n",
    "\n",
    "---\n",
    "\n",
    "## æœ¬ç« ç›®æ ‡\n",
    "\n",
    "åˆ«ç®¡åŸç†ï¼Œå…ˆè®©ä»£ç è·‘èµ·æ¥ï¼Œäº²çœ¼çœ‹åˆ°æœºå™¨å­¦ä¼šåˆ†ç±»ã€‚\n",
    "\n",
    "**ç—›ç‚¹è§£å†³ï¼š** \"æ·±åº¦å­¦ä¹ ä»£ç åˆ°åº•é•¿ä»€ä¹ˆæ ·ï¼Ÿ\"\n",
    "\n",
    "## æœ¬ç« å†…å®¹\n",
    "\n",
    "1. **æ•°æ®æ„é€ **ï¼šç”¨ sklearn ç”Ÿæˆç»å…¸çš„\"èºæ—‹å›¾\"æ•°æ®ï¼ˆçº¢è“ä¸¤ç±»ç‚¹äº¤é”™ï¼Œçº¿æ€§ä¸å¯åˆ†ï¼‰\n",
    "2. **æ­å»ºç½‘ç»œ**ï¼šç›´æ¥ç”¨ `torch.nn.Sequential` å †ä¸€ä¸ª MLPï¼ˆå¤šå±‚æ„ŸçŸ¥æœºï¼‰\n",
    "3. **è®­ç»ƒå¾ªç¯**ï¼šå†™å‡ºæ ‡å‡†çš„ `Forward -> Loss -> Backward -> Step` å¾ªç¯\n",
    "4. **å¯è§†åŒ–**ï¼šè§‚å¯Ÿç¥ç»ç½‘ç»œå¦‚ä½•å­¦ä¼šåˆ’åˆ†è¾¹ç•Œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prereq_ch0_001",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ æœ¬è¯¾ç¨‹é€‚åˆè°ï¼Ÿ\n",
    "\n",
    "### ç›®æ ‡è¯»è€…\n",
    "\n",
    "è¿™é—¨è¯¾ç¨‹é€‚åˆï¼š\n",
    "- æƒ³**æ·±å…¥ç†è§£** LLM åŸç†çš„å¼€å‘è€…\n",
    "- å·²ç»ä¼šç”¨ API è°ƒç”¨ LLMï¼Œä½†æƒ³çŸ¥é“**èƒŒåå‘ç”Ÿäº†ä»€ä¹ˆ**çš„äºº\n",
    "- æƒ³**ä»é›¶æ„å»º** LLM çš„å­¦ä¹ è€…\n",
    "\n",
    "### å‰ç½®è¦æ±‚\n",
    "\n",
    "- **Python åŸºç¡€**ï¼šå‡½æ•°ã€ç±»ã€åˆ—è¡¨ç­‰\n",
    "- **åŸºæœ¬æ•°å­¦**ï¼šå‘é‡ã€çŸ©é˜µä¹˜æ³•ï¼ˆä¸éœ€è¦ç²¾é€šï¼‰\n",
    "- **PyTorch å…¥é—¨**ï¼šèƒ½å†™ç®€å•çš„ tensor æ“ä½œï¼ˆè¯¾ç¨‹ä¼šå¤ä¹ ï¼‰\n",
    "\n",
    "### ä¸éœ€è¦\n",
    "\n",
    "- ä¸éœ€è¦æ·±åšçš„æ•°å­¦åŠŸåº•\n",
    "- ä¸éœ€è¦æœ‰æœºå™¨å­¦ä¹ ç»éªŒ\n",
    "- ä¸éœ€è¦ GPUï¼ˆå¤§éƒ¨åˆ†ä»£ç  CPU èƒ½è·‘ï¼‰\n",
    "\n",
    "### è¯¾ç¨‹ç‰¹è‰²\n",
    "\n",
    "1. **ä»£ç ä¼˜å…ˆ**ï¼šæ¯ä¸ªæ¦‚å¿µéƒ½æœ‰å¯è¿è¡Œçš„ä»£ç \n",
    "2. **å¯è§†åŒ–**ï¼šå¤§é‡å›¾è¡¨å¸®åŠ©ç†è§£\n",
    "3. **å¾ªåºæ¸è¿›**ï¼šä»æœ€ç®€å•çš„æ¦‚å¿µå¼€å§‹\n",
    "4. **å®æˆ˜å¯¼å‘**ï¼šæœ€ç»ˆèƒ½è®­ç»ƒè‡ªå·±çš„å°æ¨¡å‹\n",
    "\n",
    "### æœ¬ç« ç›®æ ‡\n",
    "\n",
    "å¿«é€Ÿè¿‡ä¸€éæ ¸å¿ƒæ¦‚å¿µï¼Œè®©ä½ å¯¹æ•´ä¸ªè¯¾ç¨‹æœ‰ä¸ªå…¨å±€è®¤è¯†ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc19ff7",
   "metadata": {},
   "source": [
    "## 0. ç¯å¢ƒå‡†å¤‡\n",
    "\n",
    "é¦–å…ˆå®‰è£…å¹¶å¯¼å…¥å¿…è¦çš„åº“ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c143e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¦‚æœéœ€è¦å®‰è£…ä¾èµ–ï¼Œå–æ¶ˆä¸‹é¢çš„æ³¨é‡Š\n",
    "# !pip install torch numpy matplotlib scikit-learn\n",
    "\n",
    "# ç¡®è®¤READMEä¸­çš„ä¾èµ–æ˜¯å¦å®Œæ¯•å®‰è£…ï¼Œ torchç‰ˆæœ¬è¯·æ ¹æ®å®é™…ç¯å¢ƒé€‰æ‹©ï¼Œæ ¹æ®readmeä¸­çš„æŒ‡å¼•å®‰è£…\n",
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e392da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons, make_circles\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­ï¼Œä¿è¯ç»“æœå¯å¤ç°\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# è®¾ç½®ä¸­æ–‡å­—ä½“ï¼ˆå¦‚æœéœ€è¦æ˜¾ç¤ºä¸­æ–‡ï¼‰\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec67da7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. æ•°æ®æ„é€ ï¼šç”Ÿæˆä¸€ä¸ª\"çº¿æ€§ä¸å¯åˆ†\"çš„ç»å…¸é—®é¢˜\n",
    "\n",
    "æˆ‘ä»¬ä½¿ç”¨ sklearn ç”Ÿæˆä¸€ä¸ªç»å…¸çš„ **æœˆäº®å½¢æ•°æ®é›† (make_moons)**ã€‚\n",
    "\n",
    "è¿™ä¸ªæ•°æ®é›†çš„ç‰¹ç‚¹æ˜¯ï¼š\n",
    "- ä¸¤ç±»æ•°æ®ç‚¹äº¤é”™æ’åˆ—\n",
    "- **æ— æ³•ç”¨ä¸€æ¡ç›´çº¿åˆ†å¼€**ï¼ˆçº¿æ€§ä¸å¯åˆ†ï¼‰\n",
    "- è¿™æ­£æ˜¯ç¥ç»ç½‘ç»œå¤§æ˜¾èº«æ‰‹çš„åœ°æ–¹ï¼\n",
    "\n",
    "### ä¸ºä»€ä¹ˆé€‰æ‹©è¿™ä¸ªæ•°æ®é›†ï¼Ÿ\n",
    "\n",
    "å¦‚æœæ•°æ®æ˜¯çº¿æ€§å¯åˆ†çš„ï¼ˆæ¯”å¦‚ä¸¤å›¢åˆ†å¼€çš„ç‚¹ï¼‰ï¼Œä¸€æ¡ç›´çº¿å°±èƒ½æå®šï¼Œç”¨ä¸ç€ç¥ç»ç½‘ç»œã€‚\n",
    "æœˆäº®å½¢æ•°æ®éœ€è¦**å¼¯æ›²çš„å†³ç­–è¾¹ç•Œ**ï¼Œè¿™æ­£å¥½å±•ç¤ºäº†ç¥ç»ç½‘ç»œçš„å¨åŠ›ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d79c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”Ÿæˆæœˆäº®å½¢æ•°æ®é›†\n",
    "n_samples = 1000\n",
    "\n",
    "X, y = make_moons(n_samples=n_samples, noise=0.1, random_state=42)\n",
    "\n",
    "# è½¬æ¢ä¸º PyTorch å¼ é‡\n",
    "X_tensor = torch.FloatTensor(X)\n",
    "y_tensor = torch.FloatTensor(y).reshape(-1, 1)  # å˜æˆåˆ—å‘é‡\n",
    "\n",
    "print(f\"æ•°æ®å½¢çŠ¶: X={X_tensor.shape}, y={y_tensor.shape}\")\n",
    "print(f\"ç‰¹å¾ç»´åº¦: {X_tensor.shape[1]} (xåæ ‡, yåæ ‡)\")\n",
    "print(f\"ç±»åˆ«: {torch.unique(y_tensor).tolist()} (0=è“è‰², 1=çº¢è‰²)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b50cdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–åŸå§‹æ•°æ®\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# åˆ†åˆ«ç»˜åˆ¶ä¸¤ç±»ç‚¹\n",
    "plt.scatter(X[y==0, 0], X[y==0, 1], c='royalblue', label='Class 0', alpha=0.6, s=30)\n",
    "plt.scatter(X[y==1, 0], X[y==1, 1], c='crimson', label='Class 1', alpha=0.6, s=30)\n",
    "\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.title('Moon Dataset - Can you draw a line to separate them?')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\næ€è€ƒï¼šä½ èƒ½ç”¨ä¸€æ¡ç›´çº¿æŠŠè“è‰²å’Œçº¢è‰²åˆ†å¼€å—ï¼Ÿ\")\n",
    "print(\"ç­”æ¡ˆï¼šä¸èƒ½ï¼è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦ç¥ç»ç½‘ç»œã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1048f44",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. æ­å»ºç¥ç»ç½‘ç»œï¼šMLP (å¤šå±‚æ„ŸçŸ¥æœº)\n",
    "\n",
    "MLP å°±æ˜¯æœ€åŸºç¡€çš„ç¥ç»ç½‘ç»œï¼Œç”±å¤šå±‚**å…¨è¿æ¥å±‚**å †å è€Œæˆã€‚\n",
    "\n",
    "### ç½‘ç»œç»“æ„\n",
    "\n",
    "```\n",
    "è¾“å…¥å±‚ (2ä¸ªç¥ç»å…ƒ) â†’ éšè—å±‚1 (32ä¸ªç¥ç»å…ƒ) â†’ éšè—å±‚2 (16ä¸ªç¥ç»å…ƒ) â†’ è¾“å‡ºå±‚ (1ä¸ªç¥ç»å…ƒ)\n",
    "      â†“                    â†“                    â†“                    â†“\n",
    "   [x1, x2]              ReLU                 ReLU               Sigmoid\n",
    "                                                                    â†“\n",
    "                                                              æ¦‚ç‡å€¼ (0~1)\n",
    "```\n",
    "\n",
    "### å…³é”®æ¦‚å¿µ\n",
    "\n",
    "- **å…¨è¿æ¥å±‚ (Linear)**ï¼šæ¯ä¸ªç¥ç»å…ƒå’Œä¸Šä¸€å±‚æ‰€æœ‰ç¥ç»å…ƒç›¸è¿\n",
    "- **ReLU æ¿€æ´»å‡½æ•°**ï¼šå¼•å…¥éçº¿æ€§ï¼Œè®©ç½‘ç»œèƒ½å­¦ä¹ å¤æ‚è¾¹ç•Œ\n",
    "- **Sigmoid**ï¼šæŠŠè¾“å‡ºå‹ç¼©åˆ° 0~1 ä¹‹é—´ï¼Œè¡¨ç¤ºæ¦‚ç‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a9e3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰ç¥ç»ç½‘ç»œæ¨¡å‹\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 32),    # è¾“å…¥å±‚ -> éšè—å±‚1: 2ç»´è¾“å…¥ï¼Œ32ä¸ªç¥ç»å…ƒ\n",
    "    nn.ReLU(),           # æ¿€æ´»å‡½æ•°: max(0, x)\n",
    "    nn.Linear(32, 16),   # éšè—å±‚1 -> éšè—å±‚2: 32ä¸ªç¥ç»å…ƒ -> 16ä¸ªç¥ç»å…ƒ\n",
    "    nn.ReLU(),           # æ¿€æ´»å‡½æ•°\n",
    "    nn.Linear(16, 1),    # éšè—å±‚2 -> è¾“å‡ºå±‚: 16ä¸ªç¥ç»å…ƒ -> 1ä¸ªè¾“å‡º\n",
    "    nn.Sigmoid()         # è¾“å‡ºæ¦‚ç‡ (0~1)\n",
    ")\n",
    "\n",
    "print(\"æ¨¡å‹ç»“æ„:\")\n",
    "print(model)\n",
    "\n",
    "# ç»Ÿè®¡å‚æ•°æ•°é‡\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"\\næ€»å‚æ•°é‡: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abb9691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®©æˆ‘ä»¬çœ‹çœ‹æ¨¡å‹å†…éƒ¨çš„å‚æ•°\n",
    "print(\"æ¨¡å‹å‚æ•°è¯¦æƒ…:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  å½¢çŠ¶: {param.shape}\")\n",
    "    print(f\"  å‚æ•°é‡: {param.numel()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33884c22",
   "metadata": {},
   "source": [
    "### ç†è§£å‚æ•°æ•°é‡\n",
    "\n",
    "| å±‚ | è®¡ç®— | å‚æ•°é‡ |\n",
    "|:---|:---|:---|\n",
    "| Linear(2â†’32) | 2Ã—32 + 32(bias) | 96 |\n",
    "| Linear(32â†’16) | 32Ã—16 + 16(bias) | 528 |\n",
    "| Linear(16â†’1) | 16Ã—1 + 1(bias) | 17 |\n",
    "| **æ€»è®¡** | | **641** |\n",
    "\n",
    "è¿™å°±æ˜¯ç¥ç»ç½‘ç»œçš„æœ¬è´¨ï¼š**ä¸€å †å¯å­¦ä¹ çš„æ•°å­—ï¼ˆæƒé‡ï¼‰**ã€‚\n",
    "\n",
    "è®­ç»ƒçš„ç›®æ ‡å°±æ˜¯è°ƒæ•´è¿™641ä¸ªæ•°å­—ï¼Œè®©ç½‘ç»œèƒ½æ­£ç¡®åˆ†ç±»ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c123156b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. è®­ç»ƒå¾ªç¯ï¼šForward â†’ Loss â†’ Backward â†’ Step\n",
    "\n",
    "è¿™æ˜¯æ·±åº¦å­¦ä¹ æœ€æ ¸å¿ƒçš„å››æ­¥å¾ªç¯ï¼Œè®°ä½å®ƒï¼\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                                                             â”‚\n",
    "â”‚   1. Forward (å‰å‘ä¼ æ’­)                                      â”‚\n",
    "â”‚      è¾“å…¥æ•°æ® â†’ ç»è¿‡ç½‘ç»œ â†’ å¾—åˆ°é¢„æµ‹ç»“æœ                        â”‚\n",
    "â”‚                         â†“                                   â”‚\n",
    "â”‚   2. Loss (è®¡ç®—æŸå¤±)                                         â”‚\n",
    "â”‚      é¢„æµ‹ç»“æœ vs çœŸå®æ ‡ç­¾ â†’ è®¡ç®—å·®è·æœ‰å¤šå¤§                     â”‚\n",
    "â”‚                         â†“                                   â”‚\n",
    "â”‚   3. Backward (åå‘ä¼ æ’­)                                     â”‚\n",
    "â”‚      è®¡ç®—æ¯ä¸ªå‚æ•°å¯¹ Loss çš„è´¡çŒ®ï¼ˆæ¢¯åº¦ï¼‰                        â”‚\n",
    "â”‚                         â†“                                   â”‚\n",
    "â”‚   4. Step (æ›´æ–°å‚æ•°)                                         â”‚\n",
    "â”‚      æ ¹æ®æ¢¯åº¦è°ƒæ•´å‚æ•°ï¼Œè®© Loss å˜å°                           â”‚\n",
    "â”‚                         â†“                                   â”‚\n",
    "â”‚                    å›åˆ°ç¬¬1æ­¥                                 â”‚\n",
    "â”‚                                                             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacc9ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨\n",
    "\n",
    "# BCE Loss: Binary Cross Entropyï¼ŒäºŒåˆ†ç±»çš„æ ‡å‡†æŸå¤±å‡½æ•°\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Adam ä¼˜åŒ–å™¨: ç›®å‰æœ€å¸¸ç”¨çš„ä¼˜åŒ–å™¨\n",
    "# lr = learning rate (å­¦ä¹ ç‡): æ¯æ¬¡æ›´æ–°å‚æ•°çš„æ­¥é•¿\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "print(\"æŸå¤±å‡½æ•°: Binary Cross Entropy (BCE)\")\n",
    "print(\"ä¼˜åŒ–å™¨: Adam\")\n",
    "print(\"å­¦ä¹ ç‡: 0.01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01865118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®­ç»ƒå¾ªç¯ - æ ¸å¿ƒä»£ç ï¼\n",
    "\n",
    "epochs = 500  # è®­ç»ƒè½®æ•°\n",
    "losses = []   # è®°å½•æ¯è½®çš„æŸå¤±\n",
    "\n",
    "print(\"å¼€å§‹è®­ç»ƒ...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # ========== 1. Forward: å‰å‘ä¼ æ’­ ==========\n",
    "    y_pred = model(X_tensor)  # è¾“å…¥æ•°æ®ï¼Œå¾—åˆ°é¢„æµ‹\n",
    "    \n",
    "    # ========== 2. Loss: è®¡ç®—æŸå¤± ==========\n",
    "    loss = criterion(y_pred, y_tensor)  # é¢„æµ‹å€¼ vs çœŸå®å€¼\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    # ========== 3. Backward: åå‘ä¼ æ’­ ==========\n",
    "    optimizer.zero_grad()  # æ¸…ç©ºä¸Šä¸€è½®çš„æ¢¯åº¦ï¼ˆé‡è¦ï¼ï¼‰\n",
    "    loss.backward()        # è®¡ç®—æ¢¯åº¦\n",
    "    \n",
    "    # ========== 4. Step: æ›´æ–°å‚æ•° ==========\n",
    "    optimizer.step()       # æ ¹æ®æ¢¯åº¦æ›´æ–°å‚æ•°\n",
    "    \n",
    "    # æ¯100è½®æ‰“å°ä¸€æ¬¡\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        # è®¡ç®—å‡†ç¡®ç‡\n",
    "        with torch.no_grad():\n",
    "            predicted = (y_pred > 0.5).float()\n",
    "            accuracy = (predicted == y_tensor).sum() / len(y_tensor) * 100\n",
    "        print(f\"Epoch [{epoch+1:3d}/{epochs}] | Loss: {loss.item():.4f} | Accuracy: {accuracy:.1f}%\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"è®­ç»ƒå®Œæˆ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b4ea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹ï¼šLoss ä¸‹é™æ›²çº¿\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(losses, color='blue', linewidth=1.5)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"åˆå§‹ Loss: {losses[0]:.4f}\")\n",
    "print(f\"æœ€ç»ˆ Loss: {losses[-1]:.4f}\")\n",
    "print(f\"Loss ä¸‹é™äº†: {(1 - losses[-1]/losses[0])*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc7778b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. å¯è§†åŒ–å†³ç­–è¾¹ç•Œï¼šè§è¯å¥‡è¿¹çš„æ—¶åˆ»ï¼\n",
    "\n",
    "ç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹è®­ç»ƒå¥½çš„ç¥ç»ç½‘ç»œæ˜¯å¦‚ä½•åˆ’åˆ†è¾¹ç•Œçš„ã€‚\n",
    "\n",
    "æˆ‘ä»¬ä¼šåœ¨æ•´ä¸ªå¹³é¢ä¸Šå¯†é›†é‡‡æ ·ç‚¹ï¼Œè®©æ¨¡å‹é¢„æµ‹æ¯ä¸ªç‚¹çš„ç±»åˆ«ï¼Œç„¶åç”»å‡º**å†³ç­–è¾¹ç•Œ**ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b05da49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(model, X, y, title=\"Decision Boundary\"):\n",
    "    \"\"\"\n",
    "    ç»˜åˆ¶å†³ç­–è¾¹ç•Œ\n",
    "    \"\"\"\n",
    "    # åˆ›å»ºç½‘æ ¼ç‚¹\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(\n",
    "        np.linspace(x_min, x_max, 200),\n",
    "        np.linspace(y_min, y_max, 200)\n",
    "    )\n",
    "    \n",
    "    # é¢„æµ‹ç½‘æ ¼ä¸Šæ¯ä¸ªç‚¹çš„ç±»åˆ«\n",
    "    grid_points = torch.FloatTensor(np.c_[xx.ravel(), yy.ravel()])\n",
    "    with torch.no_grad():\n",
    "        Z = model(grid_points).numpy().reshape(xx.shape)\n",
    "    \n",
    "    # ç»˜å›¾\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # ç”»å†³ç­–è¾¹ç•Œï¼ˆå¡«å……é¢œè‰²ï¼‰\n",
    "    plt.contourf(xx, yy, Z, levels=50, cmap='RdBu_r', alpha=0.8)\n",
    "    plt.colorbar(label='Probability of Class 1')\n",
    "    \n",
    "    # ç”»å†³ç­–è¾¹ç•Œçº¿ (æ¦‚ç‡=0.5çš„ç­‰é«˜çº¿)\n",
    "    plt.contour(xx, yy, Z, levels=[0.5], colors='white', linewidths=2)\n",
    "    \n",
    "    # ç”»æ•°æ®ç‚¹\n",
    "    plt.scatter(X[y==0, 0], X[y==0, 1], c='royalblue', edgecolors='white', \n",
    "                label='Class 0', s=40, linewidths=0.5)\n",
    "    plt.scatter(X[y==1, 0], X[y==1, 1], c='crimson', edgecolors='white', \n",
    "                label='Class 1', s=40, linewidths=0.5)\n",
    "    \n",
    "    plt.xlabel('X1')\n",
    "    plt.ylabel('X2')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "# ç»˜åˆ¶å†³ç­–è¾¹ç•Œ\n",
    "plot_decision_boundary(model, X, y, title=\"Neural Network Decision Boundary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3cf7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æœ€ç»ˆæ¨¡å‹è¯„ä¼°\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_tensor)\n",
    "    predicted_labels = (y_pred > 0.5).float()\n",
    "    accuracy = (predicted_labels == y_tensor).sum() / len(y_tensor) * 100\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"æ¨¡å‹æœ€ç»ˆè¯„ä¼°\")\n",
    "print(\"=\"*50)\n",
    "print(f\"å‡†ç¡®ç‡: {accuracy:.2f}%\")\n",
    "print(f\"æ­£ç¡®åˆ†ç±»: {int((predicted_labels == y_tensor).sum())}/{len(y_tensor)}\")\n",
    "print(f\"é”™è¯¯åˆ†ç±»: {int((predicted_labels != y_tensor).sum())}/{len(y_tensor)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4fe4ac",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. åŠ¨æ€å¯è§†åŒ–ï¼šè§‚å¯Ÿç½‘ç»œå¦‚ä½•\"å­¦ä¹ \"è¾¹ç•Œ\n",
    "\n",
    "è®©æˆ‘ä»¬é‡æ–°è®­ç»ƒï¼Œè¿™æ¬¡æ¯éš”ä¸€æ®µæ—¶é—´ä¿å­˜ä¸€ä¸‹å†³ç­–è¾¹ç•Œï¼Œçœ‹çœ‹ç½‘ç»œæ˜¯å¦‚ä½•é€æ­¥å­¦ä¼šåˆ’åˆ†çš„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4710fc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é‡æ–°åˆå§‹åŒ–æ¨¡å‹\n",
    "model_viz = nn.Sequential(\n",
    "    nn.Linear(2, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model_viz.parameters(), lr=0.01)\n",
    "\n",
    "# è®°å½•ä¸åŒepochçš„å†³ç­–è¾¹ç•Œ\n",
    "epochs_to_plot = [0, 10, 50, 100, 200, 500]\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# åˆ›å»ºç½‘æ ¼ç”¨äºç»˜å›¾\n",
    "x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "xx, yy = np.meshgrid(\n",
    "    np.linspace(x_min, x_max, 100),\n",
    "    np.linspace(y_min, y_max, 100)\n",
    ")\n",
    "grid_points = torch.FloatTensor(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "plot_idx = 0\n",
    "\n",
    "for epoch in range(501):\n",
    "    # ç»˜åˆ¶ç‰¹å®šepochçš„å†³ç­–è¾¹ç•Œ\n",
    "    if epoch in epochs_to_plot:\n",
    "        with torch.no_grad():\n",
    "            Z = model_viz(grid_points).numpy().reshape(xx.shape)\n",
    "        \n",
    "        ax = axes[plot_idx]\n",
    "        ax.contourf(xx, yy, Z, levels=50, cmap='RdBu_r', alpha=0.8)\n",
    "        ax.contour(xx, yy, Z, levels=[0.5], colors='white', linewidths=2)\n",
    "        ax.scatter(X[y==0, 0], X[y==0, 1], c='royalblue', s=15, alpha=0.6)\n",
    "        ax.scatter(X[y==1, 0], X[y==1, 1], c='crimson', s=15, alpha=0.6)\n",
    "        ax.set_title(f'Epoch {epoch}')\n",
    "        ax.set_xlabel('X1')\n",
    "        ax.set_ylabel('X2')\n",
    "        plot_idx += 1\n",
    "    \n",
    "    # è®­ç»ƒæ­¥éª¤\n",
    "    y_pred = model_viz(X_tensor)\n",
    "    loss = criterion(y_pred, y_tensor)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "plt.suptitle('Neural Network Learning Process', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nè§‚å¯Ÿï¼š\")\n",
    "print(\"- Epoch 0: éšæœºåˆå§‹åŒ–ï¼Œè¾¹ç•Œæ˜¯ä¹±çš„\")\n",
    "print(\"- Epoch 10-50: å¼€å§‹å½¢æˆè¾¹ç•Œé›å½¢\")\n",
    "print(\"- Epoch 100-200: è¾¹ç•Œè¶Šæ¥è¶Šç²¾ç¡®\")\n",
    "print(\"- Epoch 500: å®Œç¾æ‹Ÿåˆæ•°æ®åˆ†å¸ƒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af4d73f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. æŒ‘æˆ˜å‡çº§ï¼šå°è¯•æ›´å¤æ‚çš„æ•°æ®\n",
    "\n",
    "è®©æˆ‘ä»¬è¯•è¯•åŒå¿ƒåœ†æ•°æ®é›†ï¼Œçœ‹çœ‹ç¥ç»ç½‘ç»œèƒ½å¦å¤„ç†ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d641876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”ŸæˆåŒå¿ƒåœ†æ•°æ®\n",
    "X_circles, y_circles = make_circles(n_samples=1000, noise=0.05, factor=0.5, random_state=42)\n",
    "X_circles_tensor = torch.FloatTensor(X_circles)\n",
    "y_circles_tensor = torch.FloatTensor(y_circles).reshape(-1, 1)\n",
    "\n",
    "# å¯è§†åŒ–\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_circles[y_circles==0, 0], X_circles[y_circles==0, 1], c='royalblue', label='Class 0', alpha=0.6)\n",
    "plt.scatter(X_circles[y_circles==1, 0], X_circles[y_circles==1, 1], c='crimson', label='Class 1', alpha=0.6)\n",
    "plt.title('Circles Dataset - Even harder!')\n",
    "plt.legend()\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nè¿™ä¸ªæ•°æ®é›†éœ€è¦ä¸€ä¸ªå°é—­çš„åœ†å½¢è¾¹ç•Œï¼\")\n",
    "print(\"ç¥ç»ç½‘ç»œèƒ½åšåˆ°å—ï¼Ÿè®©æˆ‘ä»¬è®­ç»ƒçœ‹çœ‹...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d65bebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®­ç»ƒæ–°æ¨¡å‹å¤„ç†åŒå¿ƒåœ†æ•°æ®\n",
    "model_circles = nn.Sequential(\n",
    "    nn.Linear(2, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model_circles.parameters(), lr=0.01)\n",
    "\n",
    "# è®­ç»ƒ\n",
    "print(\"è®­ç»ƒä¸­...\")\n",
    "for epoch in range(1000):\n",
    "    y_pred = model_circles(X_circles_tensor)\n",
    "    loss = criterion(y_pred, y_circles_tensor)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 200 == 0:\n",
    "        with torch.no_grad():\n",
    "            acc = ((y_pred > 0.5).float() == y_circles_tensor).sum() / len(y_circles_tensor) * 100\n",
    "        print(f\"Epoch {epoch+1}: Loss={loss.item():.4f}, Accuracy={acc:.1f}%\")\n",
    "\n",
    "# ç»˜åˆ¶å†³ç­–è¾¹ç•Œ\n",
    "plot_decision_boundary(model_circles, X_circles, y_circles, \n",
    "                       title=\"Circles Dataset - Neural Network Found the Boundary!\")\n",
    "\n",
    "print(\"\\nç¥ç»ç½‘ç»œæˆåŠŸå­¦ä¼šäº†ç”»åœ†å½¢è¾¹ç•Œï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3160ccb9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## æœ¬ç« æ€»ç»“\n",
    "\n",
    "1. **ç¥ç»ç½‘ç»œçš„æœ¬è´¨**\n",
    "   - å°±æ˜¯ä¸€å †å¯å­¦ä¹ çš„æ•°å­—ï¼ˆæƒé‡å’Œåç½®ï¼‰\n",
    "   - é€šè¿‡çŸ©é˜µè¿ç®—å’Œæ¿€æ´»å‡½æ•°ï¼Œå¯ä»¥æ‹Ÿåˆå¤æ‚çš„è¾¹ç•Œ\n",
    "\n",
    "2. **è®­ç»ƒçš„å››æ­¥å¾ªç¯** (è®°ä½è¿™ä¸ªï¼)\n",
    "   ```python\n",
    "   y_pred = model(X)              # Forward: å‰å‘ä¼ æ’­\n",
    "   loss = criterion(y_pred, y)    # Loss: è®¡ç®—æŸå¤±\n",
    "   loss.backward()                # Backward: åå‘ä¼ æ’­ï¼ˆè®¡ç®—æ¢¯åº¦ï¼‰\n",
    "   optimizer.step()               # Step: æ›´æ–°å‚æ•°\n",
    "   ```\n",
    "\n",
    "3. **ä¸ºä»€ä¹ˆéœ€è¦ç¥ç»ç½‘ç»œ**\n",
    "   - èƒ½å¤„ç†çº¿æ€§ä¸å¯åˆ†çš„æ•°æ®\n",
    "   - è‡ªåŠ¨å­¦ä¹ å¤æ‚çš„å†³ç­–è¾¹ç•Œ\n",
    "   - è¿™å°±æ˜¯\"æ·±åº¦å­¦ä¹ \"çš„å¨åŠ›\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5424872",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## æ€è€ƒ\n",
    "\n",
    "1. **ä¿®æ”¹ç½‘ç»œç»“æ„**ï¼šå°è¯•å¢åŠ æˆ–å‡å°‘éšè—å±‚çš„ç¥ç»å…ƒæ•°é‡ï¼Œè§‚å¯Ÿå¯¹ç»“æœçš„å½±å“\n",
    "2. **ä¿®æ”¹å­¦ä¹ ç‡**ï¼šæŠŠ `lr=0.01` æ”¹æˆ `0.001` æˆ– `0.1`ï¼Œè§‚å¯Ÿè®­ç»ƒé€Ÿåº¦çš„å˜åŒ–\n",
    "3. **å¢åŠ å™ªå£°**ï¼šåœ¨ `make_moons` ä¸­æŠŠ `noise=0.1` æ”¹æˆ `0.3`ï¼Œç½‘ç»œè¿˜èƒ½å­¦å¥½å—ï¼Ÿ\n",
    "4. **æ€è€ƒé¢˜**ï¼šå¦‚æœå®Œå…¨å»æ‰ `ReLU` æ¿€æ´»å‡½æ•°ä¼šæ€æ ·ï¼Ÿï¼ˆæç¤ºï¼šçº¿æ€§å˜æ¢çš„ç»„åˆè¿˜æ˜¯çº¿æ€§å˜æ¢ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882f32a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»ƒä¹ ç©ºé—´ï¼šåœ¨è¿™é‡Œå°è¯•ä½ çš„å®éªŒ\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
