{
          "cells": [
                    {
                              "cell_type": "markdown",
                              "id": "intro",
                              "metadata": {},
                              "source": [
                                        "# Â∫îÁî®2 | RAG Á≥ªÁªüÔºöËÆ© LLM Êã•Êúâ\"ÂºÄÂç∑ËÄÉËØï\"ËÉΩÂäõ\n",
                                        "\n",
                                        "---\n",
                                        "\n",
                                        "## üéØ Êú¨ËäÇÁõÆÊ†á\n",
                                        "\n",
                                        "ÊûÑÂª∫‰∏Ä‰∏™**Áîü‰∫ßÁ∫ß RAG (Retrieval-Augmented Generation) Á≥ªÁªü**Ôºö\n",
                                        "- ‰ΩøÁî®ÁúüÂÆûÁöÑ Embedding Ê®°Âûã (SentenceTransformers)\n",
                                        "- ÂÆûÁé∞ÂÆåÊï¥ÁöÑÂêëÈáèÊï∞ÊçÆÂ∫ì\n",
                                        "- ËøûÊé•ÁúüÂÆû LLM ÁîüÊàêÂõûÁ≠î\n",
                                        "\n",
                                        "---\n",
                                        "\n",
                                        "## ‰ªÄ‰πàÊòØ RAGÔºü\n",
                                        "\n",
                                        "```\n",
                                        "Áî®Êà∑ÈóÆÈ¢ò\n",
                                        "    ‚Üì\n",
                                        "ÂêëÈáèÂåñÊü•ËØ¢ ‚Üí Âú®Áü•ËØÜÂ∫ì‰∏≠ÊêúÁ¥¢Áõ∏‰ººÊñáÊ°£\n",
                                        "    ‚Üì\n",
                                        "Â∞ÜÁõ∏ÂÖ≥ÊñáÊ°£ + ÈóÆÈ¢ò ÂèëÈÄÅÁªô LLM\n",
                                        "    ‚Üì\n",
                                        "LLM Âü∫‰∫éÊñáÊ°£ÁîüÊàêÂõûÁ≠î\n",
                                        "```\n",
                                        "\n",
                                        "**Ê†∏ÂøÉ‰ºòÂäø**Ôºö\n",
                                        "- LLM ÂèØ‰ª•ÂõûÁ≠î**ËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Ê≤°ÊúâÁöÑ‰ø°ÊÅØ**\n",
                                        "- ÂáèÂ∞ëÂπªËßâÔºàÊúâÊñáÊ°£ÊîØÊíëÔºâ\n",
                                        "- Áü•ËØÜÂèØ‰ª•ÂÆûÊó∂Êõ¥Êñ∞"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "id": "267e00ec",
                              "metadata": {},
                              "source": [
                                        "## ËøêË°åÂâçÔºöÂáÜÂ§á Ollama ÂêéÁ´Ø\n",
                                        "\n",
                                        "Â¶ÇÊûú‰Ω†ÈÄâÊã© Ollama ‰Ωú‰∏∫ÂêéÁ´ØÔºåËØ∑ÂÖàÂÆåÊàêÂáÜÂ§áÊ≠•È™§Ôºö\n",
                                        "- ÂèÇËßÅ [PREPARE_OLLAMA.ipynb](./PREPARE_OLLAMA.ipynb)\n",
                                        "\n",
                                        "ÂÆåÊàêÂêéÂÜçÁªßÁª≠Êú¨ notebook„ÄÇ\n"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "id": "setup-header",
                              "metadata": {},
                              "source": [
                                        "---\n",
                                        "\n",
                                        "## 0. ÁéØÂ¢ÉÈÖçÁΩÆ"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 2,
                              "id": "setup-imports",
                              "metadata": {},
                              "outputs": [
                                        {
                                                  "name": "stdout",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "‚úì ÁéØÂ¢ÉÂáÜÂ§áÂÆåÊàê!\n"
                                                  ]
                                        }
                              ],
                              "source": [
                                        "import sys\n",
                                        "import os\n",
                                        "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
                                        "\n",
                                        "import numpy as np\n",
                                        "from typing import List, Dict, Tuple, Optional\n",
                                        "from dataclasses import dataclass\n",
                                        "import json\n",
                                        "\n",
                                        "# ÂØºÂÖ•Áªü‰∏ÄÁöÑÂêéÁ´ØÊé•Âè£\n",
                                        "from utils.llm_backend import get_llm_backend\n",
                                        "from utils.embedding_backend import get_embedding_backend, SimpleVectorStore\n",
                                        "\n",
                                        "print(\"‚úì ÁéØÂ¢ÉÂáÜÂ§áÂÆåÊàê!\")"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "id": "da830dbd",
                              "metadata": {},
                              "source": [
                                        "## Ê≥®ÊÑèÁΩëÁªúËøûÊé• ‰ΩøÁî®sentence transformer"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 4,
                              "id": "setup-backends",
                              "metadata": {},
                              "outputs": [
                                        {
                                                  "name": "stdout",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "Ê≠£Âú®Âä†ËΩΩ Embedding Ê®°Âûã: paraphrase-multilingual-MiniLM-L12-v2...\n",
                                                            "‚úì Ê®°ÂûãÂä†ËΩΩÂÆåÊàê! Áª¥Â∫¶: 384\n",
                                                            "‚úì Embedding Ê®°ÂûãÂä†ËΩΩÊàêÂäüÔºåÁª¥Â∫¶: 384\n",
                                                            "‚úì LLM ËøûÊé•ÊàêÂäü\n"
                                                  ]
                                        }
                              ],
                              "source": [
                                        "# ============================================================\n",
                                        "# ÈÖçÁΩÆ Embedding Âíå LLM ÂêéÁ´Ø\n",
                                        "# ============================================================\n",
                                        "\n",
                                        "# Embedding Ê®°Âûã (Êé®Ëçê‰ΩøÁî® sentence-transformers)\n",
                                        "try:\n",
                                        "    # Â§öËØ≠Ë®ÄÊ®°ÂûãÔºåÊîØÊåÅ‰∏≠Ëã±Êñá\n",
                                        "    embedder = get_embedding_backend(\n",
                                        "        \"sentence-transformers\",\n",
                                        "        model=\"paraphrase-multilingual-MiniLM-L12-v2\"  # Â§öËØ≠Ë®Ä\n",
                                        "        # model=\"all-MiniLM-L6-v2\"  # ‰ªÖËã±ÊñáÔºåÊõ¥Âø´\n",
                                        "    )\n",
                                        "    print(f\"‚úì Embedding Ê®°ÂûãÂä†ËΩΩÊàêÂäüÔºåÁª¥Â∫¶: {embedder.dimension}\")\n",
                                        "except Exception as e:\n",
                                        "    print(f\"‚ö†Ô∏è sentence-transformers ‰∏çÂèØÁî®: {e}\")\n",
                                        "    print(\"‰ΩøÁî® TF-IDF Â§áÈÄâÊñπÊ°à...\")\n",
                                        "    from utils.embedding_backend import TFIDFEmbeddingBackend\n",
                                        "    embedder = TFIDFEmbeddingBackend()\n",
                                        "\n",
                                        "def check_ollama_ready(host=\"http://localhost:11434\"):\n",
                                        "    try:\n",
                                        "        import requests\n",
                                        "        resp = requests.get(f\"{host}/api/tags\", timeout=2)\n",
                                        "        return resp.status_code == 200\n",
                                        "    except Exception:\n",
                                        "        return False\n",
                                        "\n",
                                        "# LLM ÂêéÁ´Ø\n",
                                        "if not check_ollama_ready():\n",
                                        "    print(\"Ollama Êú™ÂêØÂä®„ÄÇËØ∑ÂÖàÊâßË°å: ollama serve\")\n",
                                        "    print(\"Âπ∂‰∏ãËΩΩÊ®°Âûã: ollama pull qwen3:4b\")\n",
                                        "try:\n",
                                        "    llm = get_llm_backend(\"ollama\", model=\"qwen3:4b\")\n",
                                        "    test = llm.chat([{\"role\": \"user\", \"content\": \"Hi\"}])\n",
                                        "    print(f\"‚úì LLM ËøûÊé•ÊàêÂäü\")\n",
                                        "except Exception as e:\n",
                                        "    print(f\"‚ö†Ô∏è Ollama ‰∏çÂèØÁî®: {e}\")\n",
                                        "    try:\n",
                                        "        llm = get_llm_backend(\"openai\", model=\"gpt-3.5-turbo\")\n",
                                        "        print(\"‚úì ‰ΩøÁî® OpenAI ÂêéÁ´Ø\")\n",
                                        "    except:\n",
                                        "        llm = None\n",
                                        "        print(\"‚ùå ËØ∑ÈÖçÁΩÆ LLM ÂêéÁ´Ø\")"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "id": "vector-db-header",
                              "metadata": {},
                              "source": [
                                        "---\n",
                                        "\n",
                                        "## 1. ÂêëÈáèÊï∞ÊçÆÂ∫ìÂÆûÁé∞\n",
                                        "\n",
                                        "Êàë‰ª¨‰ΩøÁî® `SimpleVectorStore`ÔºåÂÆÉÊîØÊåÅÔºö\n",
                                        "- Ê∑ªÂä†ÊñáÊ°£Âπ∂Ëá™Âä®ÂêëÈáèÂåñ\n",
                                        "- ‰ΩôÂº¶Áõ∏‰ººÂ∫¶ÊêúÁ¥¢\n",
                                        "- ÊåÅ‰πÖÂåñÂ≠òÂÇ®"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 5,
                              "id": "create-vector-store",
                              "metadata": {},
                              "outputs": [
                                        {
                                                  "name": "stdout",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "‚úì Â∑≤Ê∑ªÂä† 15 ‰∏™ÊñáÊ°£ÔºåÊÄªËÆ° 15 ‰∏™\n"
                                                  ]
                                        }
                              ],
                              "source": [
                                        "# ÂàõÂª∫ÂêëÈáèÊï∞ÊçÆÂ∫ì\n",
                                        "vector_store = SimpleVectorStore(embedder)\n",
                                        "\n",
                                        "# ÂáÜÂ§áÁü•ËØÜÂ∫ìÊñáÊ°£\n",
                                        "documents = [\n",
                                        "    # LLM Âü∫Á°ÄÁü•ËØÜ\n",
                                        "    \"TransformerÊòØ2017Âπ¥GoogleÂú®ËÆ∫Êñá'Attention is All You Need'‰∏≠ÊèêÂá∫ÁöÑÊ∑±Â∫¶Â≠¶‰π†Êû∂ÊûÑ„ÄÇÂÆÉÂºïÂÖ•‰∫ÜËá™Ê≥®ÊÑèÂäõÊú∫Âà∂ÔºåËÉΩÂ§üÂπ∂Ë°åÂ§ÑÁêÜÂ∫èÂàóÊï∞ÊçÆÔºåÊàê‰∏∫Áé∞‰ª£Â§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÂü∫Á°Ä„ÄÇ\",\n",
                                        "    \"GPT (Generative Pre-trained Transformer) ÊòØOpenAIÂºÄÂèëÁöÑËØ≠Ë®ÄÊ®°ÂûãÁ≥ªÂàó„ÄÇGPT-3Êúâ1750‰∫øÂèÇÊï∞ÔºåGPT-4ÊòØÂ§öÊ®°ÊÄÅÊ®°ÂûãÔºåËÉΩÂ§üÂ§ÑÁêÜÂõæÂÉèÂíåÊñáÊú¨„ÄÇ\",\n",
                                        "    \"BERT (Bidirectional Encoder Representations from Transformers) ÊòØGoogleÂºÄÂèëÁöÑÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°ÂûãÔºåÈááÁî®ÂèåÂêëTransformerÁºñÁ†ÅÂô®ÔºåÂú®NLU‰ªªÂä°‰∏äË°®Áé∞‰ºòÁßÄ„ÄÇ\",\n",
                                        "    \"LLaMAÊòØMetaÂºÄÂèëÁöÑÂºÄÊ∫êÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁ≥ªÂàó„ÄÇLLaMA 2Êúâ7B„ÄÅ13B„ÄÅ70B‰∏â‰∏™ÁâàÊú¨ÔºåÊîØÊåÅÂïÜ‰∏ö‰ΩøÁî®„ÄÇLLaMA 3Ëøõ‰∏ÄÊ≠•ÊèêÂçá‰∫ÜÊÄßËÉΩ„ÄÇ\",\n",
                                        "    \"ChatGPTÊòØÂü∫‰∫éGPT-3.5ÂíåGPT-4ÁöÑÂØπËØùAIÔºå‰∫é2022Âπ¥11ÊúàÂèëÂ∏ÉÔºå‰∏§‰∏™ÊúàÂÜÖÁî®Êà∑Á™ÅÁ†¥1‰∫ø„ÄÇÂÆÉ‰ΩøÁî®RLHFÊäÄÊúØËøõË°åÂØπÈΩêËÆ≠ÁªÉ„ÄÇ\",\n",
                                        "    \n",
                                        "    # ËÆ≠ÁªÉÊäÄÊúØ\n",
                                        "    \"È¢ÑËÆ≠ÁªÉ(Pre-training)ÊòØÂú®Â§ßËßÑÊ®°Êó†Ê†áÊ≥®ÊñáÊú¨‰∏äËÆ≠ÁªÉËØ≠Ë®ÄÊ®°ÂûãÔºåËÆ©Ê®°ÂûãÂ≠¶‰π†ËØ≠Ë®ÄÁöÑÁªüËÆ°ËßÑÂæã„ÄÇÂ∏∏Áî®ÁõÆÊ†áÂåÖÊã¨Next Token PredictionÂíåMasked Language Modeling„ÄÇ\",\n",
                                        "    \"SFT (Supervised Fine-Tuning) ÊòØÁõëÁù£ÂæÆË∞ÉÔºå‰ΩøÁî®È´òË¥®ÈáèÁöÑÊåá‰ª§-ÂõûÁ≠îÂØπËÆ≠ÁªÉÊ®°ÂûãÔºåËÆ©Ê®°ÂûãÂ≠¶‰ºöÈÅµÂæ™Êåá‰ª§„ÄÇËøôÊòØÊääBase ModelÂèòÊàêChat ModelÁöÑÂÖ≥ÈîÆÊ≠•È™§„ÄÇ\",\n",
                                        "    \"RLHF (Reinforcement Learning from Human Feedback) ‰ΩøÁî®‰∫∫Á±ªÂèçÈ¶àÊù•‰ºòÂåñÊ®°Âûã„ÄÇÊµÅÁ®ãÂåÖÊã¨Ôºö1)ËÆ≠ÁªÉReward Model 2)‰ΩøÁî®PPO‰ºòÂåñÁ≠ñÁï•Ê®°Âûã„ÄÇ\",\n",
                                        "    \"DPO (Direct Preference Optimization) ÊòØ‰∏ÄÁßçÁÆÄÂåñÁöÑÂØπÈΩêÊñπÊ≥ïÔºåÁõ¥Êé•‰ªéÂÅèÂ•ΩÊï∞ÊçÆÂ≠¶‰π†Ôºå‰∏çÈúÄË¶ÅËÆ≠ÁªÉÂçïÁã¨ÁöÑReward ModelÔºåËÆ≠ÁªÉÊõ¥Á®≥ÂÆö„ÄÇ\",\n",
                                        "    \"LoRA (Low-Rank Adaptation) ÊòØ‰∏ÄÁßçÂèÇÊï∞È´òÊïàÂæÆË∞ÉÊñπÊ≥ïÔºåÂè™ËÆ≠ÁªÉ‰ΩéÁß©Áü©ÈòµÔºåÂ§ßÂ§ßÂáèÂ∞ëÂèØËÆ≠ÁªÉÂèÇÊï∞ÈáèÔºåËÆ©Ê∂àË¥πÁ∫ßÊòæÂç°‰πüËÉΩÂæÆË∞ÉÂ§ßÊ®°Âûã„ÄÇ\",\n",
                                        "    \n",
                                        "    # ÊäÄÊúØÁªÜËäÇ\n",
                                        "    \"Ëá™Ê≥®ÊÑèÂäõÊú∫Âà∂(Self-Attention)ËÆ©Ê®°ÂûãËÉΩÂ§üÂÖ≥Ê≥®ËæìÂÖ•Â∫èÂàó‰∏≠ÁöÑ‰∏çÂêå‰ΩçÁΩÆÔºåÈÄöËøáQ„ÄÅK„ÄÅVÁü©ÈòµËÆ°ÁÆóÊ≥®ÊÑèÂäõÊùÉÈáçÔºåÊçïÊçâÈïøË∑ùÁ¶ª‰æùËµñÂÖ≥Á≥ª„ÄÇ\",\n",
                                        "    \"KV CacheÊòØÊé®ÁêÜÂä†ÈÄüÊäÄÊúØÔºåÁºìÂ≠òÂ∑≤ËÆ°ÁÆóÁöÑKeyÂíåValueÁü©ÈòµÔºåÈÅøÂÖçÈáçÂ§çËÆ°ÁÆóÔºåÂèØ‰ª•ÊòæËëóÊèêÂçáËá™ÂõûÂΩíÁîüÊàêÁöÑÈÄüÂ∫¶„ÄÇ\",\n",
                                        "    \"ÈáèÂåñ(Quantization)ÈÄöËøáÈôç‰ΩéÂèÇÊï∞Á≤æÂ∫¶(FP16‚ÜíINT8‚ÜíINT4)Êù•ÂáèÂ∞ëÂÜÖÂ≠òÂç†Áî®„ÄÇ4-bitÈáèÂåñÂèØ‰ª•ËÆ©7BÊ®°ÂûãÂè™ÈúÄË¶Å4GBÊòæÂ≠ò„ÄÇ\",\n",
                                        "    \"RAG (Retrieval-Augmented Generation) ÁªìÂêàÊ£ÄÁ¥¢ÂíåÁîüÊàêÔºåÂÖà‰ªéÁü•ËØÜÂ∫ìÊ£ÄÁ¥¢Áõ∏ÂÖ≥ÊñáÊ°£ÔºåÂÜçËÆ©LLMÂü∫‰∫éÊñáÊ°£ÁîüÊàêÂõûÁ≠îÔºåÂáèÂ∞ëÂπªËßâ„ÄÇ\",\n",
                                        "    \"AgentÊòØËÉΩÂ§üËá™‰∏ªËßÑÂàíÂíåÊâßË°å‰ªªÂä°ÁöÑAIÁ≥ªÁªü„ÄÇReActÊ®°ÂºèËÆ©AgentÈÄöËøáÊÄùËÄÉ-Ë°åÂä®-ËßÇÂØüÂæ™ÁéØÊù•Ëß£ÂÜ≥ÈóÆÈ¢òÔºåÂèØ‰ª•Ë∞ÉÁî®Â§ñÈÉ®Â∑•ÂÖ∑„ÄÇ\",\n",
                                        "]\n",
                                        "\n",
                                        "# Ê∑ªÂä†ÂÖÉÊï∞ÊçÆ\n",
                                        "metadata = [\n",
                                        "    {\"topic\": \"architecture\", \"id\": 1},\n",
                                        "    {\"topic\": \"models\", \"id\": 2},\n",
                                        "    {\"topic\": \"models\", \"id\": 3},\n",
                                        "    {\"topic\": \"models\", \"id\": 4},\n",
                                        "    {\"topic\": \"models\", \"id\": 5},\n",
                                        "    {\"topic\": \"training\", \"id\": 6},\n",
                                        "    {\"topic\": \"training\", \"id\": 7},\n",
                                        "    {\"topic\": \"training\", \"id\": 8},\n",
                                        "    {\"topic\": \"training\", \"id\": 9},\n",
                                        "    {\"topic\": \"training\", \"id\": 10},\n",
                                        "    {\"topic\": \"technical\", \"id\": 11},\n",
                                        "    {\"topic\": \"technical\", \"id\": 12},\n",
                                        "    {\"topic\": \"technical\", \"id\": 13},\n",
                                        "    {\"topic\": \"technical\", \"id\": 14},\n",
                                        "    {\"topic\": \"technical\", \"id\": 15},\n",
                                        "]\n",
                                        "\n",
                                        "# Ê∑ªÂä†Âà∞ÂêëÈáèÊï∞ÊçÆÂ∫ì\n",
                                        "vector_store.add_documents(documents, metadata)"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "id": "search-header",
                              "metadata": {},
                              "source": [
                                        "---\n",
                                        "\n",
                                        "## 2. ÊµãËØïÂêëÈáèÊêúÁ¥¢"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 6,
                              "id": "test-search",
                              "metadata": {},
                              "outputs": [
                                        {
                                                  "name": "stdout",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "\n",
                                                            "üîç Êü•ËØ¢: ‰ªÄ‰πàÊòØTransformerÔºü\n",
                                                            "------------------------------------------------------------\n",
                                                            "\n",
                                                            "üìÑ ÁªìÊûú 1 (Áõ∏‰ººÂ∫¶: 0.5470)\n",
                                                            "   ‰∏ªÈ¢ò: architecture\n",
                                                            "   ÂÜÖÂÆπ: TransformerÊòØ2017Âπ¥GoogleÂú®ËÆ∫Êñá'Attention is All You Need'‰∏≠ÊèêÂá∫ÁöÑÊ∑±Â∫¶Â≠¶‰π†Êû∂ÊûÑ„ÄÇÂÆÉÂºïÂÖ•‰∫ÜËá™Ê≥®ÊÑèÂäõÊú∫Âà∂ÔºåËÉΩÂ§üÂπ∂Ë°åÂ§ÑÁêÜÂ∫èÂàóÊï∞ÊçÆÔºåÊàê‰∏∫Áé∞‰ª£Â§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÂü∫Á°Ä„ÄÇ...\n",
                                                            "\n",
                                                            "üìÑ ÁªìÊûú 2 (Áõ∏‰ººÂ∫¶: 0.5257)\n",
                                                            "   ‰∏ªÈ¢ò: models\n",
                                                            "   ÂÜÖÂÆπ: BERT (Bidirectional Encoder Representations from Transformers) ÊòØGoogleÂºÄÂèëÁöÑÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°ÂûãÔºåÈááÁî®ÂèåÂêëTransformerÁºñÁ†ÅÂô®Ôºå...\n",
                                                            "\n",
                                                            "üìÑ ÁªìÊûú 3 (Áõ∏‰ººÂ∫¶: 0.3722)\n",
                                                            "   ‰∏ªÈ¢ò: models\n",
                                                            "   ÂÜÖÂÆπ: GPT (Generative Pre-trained Transformer) ÊòØOpenAIÂºÄÂèëÁöÑËØ≠Ë®ÄÊ®°ÂûãÁ≥ªÂàó„ÄÇGPT-3Êúâ1750‰∫øÂèÇÊï∞ÔºåGPT-4ÊòØÂ§öÊ®°ÊÄÅÊ®°ÂûãÔºåËÉΩÂ§üÂ§ÑÁêÜÂõæÂÉèÂíåÊñáÊú¨„ÄÇ...\n"
                                                  ]
                                        },
                                        {
                                                  "data": {
                                                            "text/plain": [
                                                                      "[{'document': \"TransformerÊòØ2017Âπ¥GoogleÂú®ËÆ∫Êñá'Attention is All You Need'‰∏≠ÊèêÂá∫ÁöÑÊ∑±Â∫¶Â≠¶‰π†Êû∂ÊûÑ„ÄÇÂÆÉÂºïÂÖ•‰∫ÜËá™Ê≥®ÊÑèÂäõÊú∫Âà∂ÔºåËÉΩÂ§üÂπ∂Ë°åÂ§ÑÁêÜÂ∫èÂàóÊï∞ÊçÆÔºåÊàê‰∏∫Áé∞‰ª£Â§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÂü∫Á°Ä„ÄÇ\",\n",
                                                                      "  'score': 0.547032356262207,\n",
                                                                      "  'metadata': {'topic': 'architecture', 'id': 1}},\n",
                                                                      " {'document': 'BERT (Bidirectional Encoder Representations from Transformers) ÊòØGoogleÂºÄÂèëÁöÑÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°ÂûãÔºåÈááÁî®ÂèåÂêëTransformerÁºñÁ†ÅÂô®ÔºåÂú®NLU‰ªªÂä°‰∏äË°®Áé∞‰ºòÁßÄ„ÄÇ',\n",
                                                                      "  'score': 0.5257304310798645,\n",
                                                                      "  'metadata': {'topic': 'models', 'id': 3}},\n",
                                                                      " {'document': 'GPT (Generative Pre-trained Transformer) ÊòØOpenAIÂºÄÂèëÁöÑËØ≠Ë®ÄÊ®°ÂûãÁ≥ªÂàó„ÄÇGPT-3Êúâ1750‰∫øÂèÇÊï∞ÔºåGPT-4ÊòØÂ§öÊ®°ÊÄÅÊ®°ÂûãÔºåËÉΩÂ§üÂ§ÑÁêÜÂõæÂÉèÂíåÊñáÊú¨„ÄÇ',\n",
                                                                      "  'score': 0.3721601963043213,\n",
                                                                      "  'metadata': {'topic': 'models', 'id': 2}}]"
                                                            ]
                                                  },
                                                  "execution_count": 6,
                                                  "metadata": {},
                                                  "output_type": "execute_result"
                                        }
                              ],
                              "source": [
                                        "def pretty_search(query: str, top_k: int = 3):\n",
                                        "    \"\"\"Ê†ºÂºèÂåñÊòæÁ§∫ÊêúÁ¥¢ÁªìÊûú\"\"\"\n",
                                        "    print(f\"\\nüîç Êü•ËØ¢: {query}\")\n",
                                        "    print(\"-\" * 60)\n",
                                        "    \n",
                                        "    results = vector_store.search(query, top_k=top_k)\n",
                                        "    \n",
                                        "    for i, result in enumerate(results, 1):\n",
                                        "        print(f\"\\nüìÑ ÁªìÊûú {i} (Áõ∏‰ººÂ∫¶: {result['score']:.4f})\")\n",
                                        "        print(f\"   ‰∏ªÈ¢ò: {result['metadata'].get('topic', 'N/A')}\")\n",
                                        "        print(f\"   ÂÜÖÂÆπ: {result['document'][:100]}...\")\n",
                                        "    \n",
                                        "    return results\n",
                                        "\n",
                                        "# ÊµãËØïÊêúÁ¥¢\n",
                                        "pretty_search(\"‰ªÄ‰πàÊòØTransformerÔºü\")"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 7,
                              "id": "test-search-2",
                              "metadata": {},
                              "outputs": [
                                        {
                                                  "name": "stdout",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "\n",
                                                            "üîç Êü•ËØ¢: Â¶Ç‰ΩïËÆ≠ÁªÉÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºü\n",
                                                            "------------------------------------------------------------\n",
                                                            "\n",
                                                            "üìÑ ÁªìÊûú 1 (Áõ∏‰ººÂ∫¶: 0.6368)\n",
                                                            "   ‰∏ªÈ¢ò: training\n",
                                                            "   ÂÜÖÂÆπ: È¢ÑËÆ≠ÁªÉ(Pre-training)ÊòØÂú®Â§ßËßÑÊ®°Êó†Ê†áÊ≥®ÊñáÊú¨‰∏äËÆ≠ÁªÉËØ≠Ë®ÄÊ®°ÂûãÔºåËÆ©Ê®°ÂûãÂ≠¶‰π†ËØ≠Ë®ÄÁöÑÁªüËÆ°ËßÑÂæã„ÄÇÂ∏∏Áî®ÁõÆÊ†áÂåÖÊã¨Next Token PredictionÂíåMasked Language Modeling...\n",
                                                            "\n",
                                                            "üìÑ ÁªìÊûú 2 (Áõ∏‰ººÂ∫¶: 0.4671)\n",
                                                            "   ‰∏ªÈ¢ò: training\n",
                                                            "   ÂÜÖÂÆπ: SFT (Supervised Fine-Tuning) ÊòØÁõëÁù£ÂæÆË∞ÉÔºå‰ΩøÁî®È´òË¥®ÈáèÁöÑÊåá‰ª§-ÂõûÁ≠îÂØπËÆ≠ÁªÉÊ®°ÂûãÔºåËÆ©Ê®°ÂûãÂ≠¶‰ºöÈÅµÂæ™Êåá‰ª§„ÄÇËøôÊòØÊääBase ModelÂèòÊàêChat ModelÁöÑÂÖ≥ÈîÆÊ≠•È™§„ÄÇ...\n",
                                                            "\n",
                                                            "üìÑ ÁªìÊûú 3 (Áõ∏‰ººÂ∫¶: 0.4565)\n",
                                                            "   ‰∏ªÈ¢ò: models\n",
                                                            "   ÂÜÖÂÆπ: BERT (Bidirectional Encoder Representations from Transformers) ÊòØGoogleÂºÄÂèëÁöÑÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°ÂûãÔºåÈááÁî®ÂèåÂêëTransformerÁºñÁ†ÅÂô®Ôºå...\n"
                                                  ]
                                        },
                                        {
                                                  "data": {
                                                            "text/plain": [
                                                                      "[{'document': 'È¢ÑËÆ≠ÁªÉ(Pre-training)ÊòØÂú®Â§ßËßÑÊ®°Êó†Ê†áÊ≥®ÊñáÊú¨‰∏äËÆ≠ÁªÉËØ≠Ë®ÄÊ®°ÂûãÔºåËÆ©Ê®°ÂûãÂ≠¶‰π†ËØ≠Ë®ÄÁöÑÁªüËÆ°ËßÑÂæã„ÄÇÂ∏∏Áî®ÁõÆÊ†áÂåÖÊã¨Next Token PredictionÂíåMasked Language Modeling„ÄÇ',\n",
                                                                      "  'score': 0.6367638111114502,\n",
                                                                      "  'metadata': {'topic': 'training', 'id': 6}},\n",
                                                                      " {'document': 'SFT (Supervised Fine-Tuning) ÊòØÁõëÁù£ÂæÆË∞ÉÔºå‰ΩøÁî®È´òË¥®ÈáèÁöÑÊåá‰ª§-ÂõûÁ≠îÂØπËÆ≠ÁªÉÊ®°ÂûãÔºåËÆ©Ê®°ÂûãÂ≠¶‰ºöÈÅµÂæ™Êåá‰ª§„ÄÇËøôÊòØÊääBase ModelÂèòÊàêChat ModelÁöÑÂÖ≥ÈîÆÊ≠•È™§„ÄÇ',\n",
                                                                      "  'score': 0.46705737709999084,\n",
                                                                      "  'metadata': {'topic': 'training', 'id': 7}},\n",
                                                                      " {'document': 'BERT (Bidirectional Encoder Representations from Transformers) ÊòØGoogleÂºÄÂèëÁöÑÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°ÂûãÔºåÈááÁî®ÂèåÂêëTransformerÁºñÁ†ÅÂô®ÔºåÂú®NLU‰ªªÂä°‰∏äË°®Áé∞‰ºòÁßÄ„ÄÇ',\n",
                                                                      "  'score': 0.45646658539772034,\n",
                                                                      "  'metadata': {'topic': 'models', 'id': 3}}]"
                                                            ]
                                                  },
                                                  "execution_count": 7,
                                                  "metadata": {},
                                                  "output_type": "execute_result"
                                        }
                              ],
                              "source": [
                                        "# Êõ¥Â§öÊêúÁ¥¢ÊµãËØï\n",
                                        "pretty_search(\"Â¶Ç‰ΩïËÆ≠ÁªÉÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºü\")"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 8,
                              "id": "test-search-3",
                              "metadata": {},
                              "outputs": [
                                        {
                                                  "name": "stdout",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "\n",
                                                            "üîç Êü•ËØ¢: LoRA ÊòØ‰ªÄ‰πàÔºüÂ¶Ç‰ΩïÂáèÂ∞ëÊòæÂ≠òÔºü\n",
                                                            "------------------------------------------------------------\n",
                                                            "\n",
                                                            "üìÑ ÁªìÊûú 1 (Áõ∏‰ººÂ∫¶: 0.6748)\n",
                                                            "   ‰∏ªÈ¢ò: training\n",
                                                            "   ÂÜÖÂÆπ: LoRA (Low-Rank Adaptation) ÊòØ‰∏ÄÁßçÂèÇÊï∞È´òÊïàÂæÆË∞ÉÊñπÊ≥ïÔºåÂè™ËÆ≠ÁªÉ‰ΩéÁß©Áü©ÈòµÔºåÂ§ßÂ§ßÂáèÂ∞ëÂèØËÆ≠ÁªÉÂèÇÊï∞ÈáèÔºåËÆ©Ê∂àË¥πÁ∫ßÊòæÂç°‰πüËÉΩÂæÆË∞ÉÂ§ßÊ®°Âûã„ÄÇ...\n",
                                                            "\n",
                                                            "üìÑ ÁªìÊûú 2 (Áõ∏‰ººÂ∫¶: 0.3575)\n",
                                                            "   ‰∏ªÈ¢ò: models\n",
                                                            "   ÂÜÖÂÆπ: LLaMAÊòØMetaÂºÄÂèëÁöÑÂºÄÊ∫êÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁ≥ªÂàó„ÄÇLLaMA 2Êúâ7B„ÄÅ13B„ÄÅ70B‰∏â‰∏™ÁâàÊú¨ÔºåÊîØÊåÅÂïÜ‰∏ö‰ΩøÁî®„ÄÇLLaMA 3Ëøõ‰∏ÄÊ≠•ÊèêÂçá‰∫ÜÊÄßËÉΩ„ÄÇ...\n",
                                                            "\n",
                                                            "üìÑ ÁªìÊûú 3 (Áõ∏‰ººÂ∫¶: 0.3319)\n",
                                                            "   ‰∏ªÈ¢ò: technical\n",
                                                            "   ÂÜÖÂÆπ: RAG (Retrieval-Augmented Generation) ÁªìÂêàÊ£ÄÁ¥¢ÂíåÁîüÊàêÔºåÂÖà‰ªéÁü•ËØÜÂ∫ìÊ£ÄÁ¥¢Áõ∏ÂÖ≥ÊñáÊ°£ÔºåÂÜçËÆ©LLMÂü∫‰∫éÊñáÊ°£ÁîüÊàêÂõûÁ≠îÔºåÂáèÂ∞ëÂπªËßâ„ÄÇ...\n"
                                                  ]
                                        },
                                        {
                                                  "data": {
                                                            "text/plain": [
                                                                      "[{'document': 'LoRA (Low-Rank Adaptation) ÊòØ‰∏ÄÁßçÂèÇÊï∞È´òÊïàÂæÆË∞ÉÊñπÊ≥ïÔºåÂè™ËÆ≠ÁªÉ‰ΩéÁß©Áü©ÈòµÔºåÂ§ßÂ§ßÂáèÂ∞ëÂèØËÆ≠ÁªÉÂèÇÊï∞ÈáèÔºåËÆ©Ê∂àË¥πÁ∫ßÊòæÂç°‰πüËÉΩÂæÆË∞ÉÂ§ßÊ®°Âûã„ÄÇ',\n",
                                                                      "  'score': 0.6748276948928833,\n",
                                                                      "  'metadata': {'topic': 'training', 'id': 10}},\n",
                                                                      " {'document': 'LLaMAÊòØMetaÂºÄÂèëÁöÑÂºÄÊ∫êÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁ≥ªÂàó„ÄÇLLaMA 2Êúâ7B„ÄÅ13B„ÄÅ70B‰∏â‰∏™ÁâàÊú¨ÔºåÊîØÊåÅÂïÜ‰∏ö‰ΩøÁî®„ÄÇLLaMA 3Ëøõ‰∏ÄÊ≠•ÊèêÂçá‰∫ÜÊÄßËÉΩ„ÄÇ',\n",
                                                                      "  'score': 0.35746684670448303,\n",
                                                                      "  'metadata': {'topic': 'models', 'id': 4}},\n",
                                                                      " {'document': 'RAG (Retrieval-Augmented Generation) ÁªìÂêàÊ£ÄÁ¥¢ÂíåÁîüÊàêÔºåÂÖà‰ªéÁü•ËØÜÂ∫ìÊ£ÄÁ¥¢Áõ∏ÂÖ≥ÊñáÊ°£ÔºåÂÜçËÆ©LLMÂü∫‰∫éÊñáÊ°£ÁîüÊàêÂõûÁ≠îÔºåÂáèÂ∞ëÂπªËßâ„ÄÇ',\n",
                                                                      "  'score': 0.33194488286972046,\n",
                                                                      "  'metadata': {'topic': 'technical', 'id': 14}}]"
                                                            ]
                                                  },
                                                  "execution_count": 8,
                                                  "metadata": {},
                                                  "output_type": "execute_result"
                                        }
                              ],
                              "source": [
                                        "pretty_search(\"LoRA ÊòØ‰ªÄ‰πàÔºüÂ¶Ç‰ΩïÂáèÂ∞ëÊòæÂ≠òÔºü\")"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 9,
                              "id": "test-search-4",
                              "metadata": {},
                              "outputs": [
                                        {
                                                  "name": "stdout",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "\n",
                                                            "üîç Êü•ËØ¢: What is RLHF and how does it work?\n",
                                                            "------------------------------------------------------------\n",
                                                            "\n",
                                                            "üìÑ ÁªìÊûú 1 (Áõ∏‰ººÂ∫¶: 0.4759)\n",
                                                            "   ‰∏ªÈ¢ò: training\n",
                                                            "   ÂÜÖÂÆπ: RLHF (Reinforcement Learning from Human Feedback) ‰ΩøÁî®‰∫∫Á±ªÂèçÈ¶àÊù•‰ºòÂåñÊ®°Âûã„ÄÇÊµÅÁ®ãÂåÖÊã¨Ôºö1)ËÆ≠ÁªÉReward Model 2)‰ΩøÁî®PPO‰ºòÂåñÁ≠ñÁï•Ê®°Âûã„ÄÇ...\n",
                                                            "\n",
                                                            "üìÑ ÁªìÊûú 2 (Áõ∏‰ººÂ∫¶: 0.3984)\n",
                                                            "   ‰∏ªÈ¢ò: models\n",
                                                            "   ÂÜÖÂÆπ: LLaMAÊòØMetaÂºÄÂèëÁöÑÂºÄÊ∫êÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁ≥ªÂàó„ÄÇLLaMA 2Êúâ7B„ÄÅ13B„ÄÅ70B‰∏â‰∏™ÁâàÊú¨ÔºåÊîØÊåÅÂïÜ‰∏ö‰ΩøÁî®„ÄÇLLaMA 3Ëøõ‰∏ÄÊ≠•ÊèêÂçá‰∫ÜÊÄßËÉΩ„ÄÇ...\n",
                                                            "\n",
                                                            "üìÑ ÁªìÊûú 3 (Áõ∏‰ººÂ∫¶: 0.3848)\n",
                                                            "   ‰∏ªÈ¢ò: models\n",
                                                            "   ÂÜÖÂÆπ: ChatGPTÊòØÂü∫‰∫éGPT-3.5ÂíåGPT-4ÁöÑÂØπËØùAIÔºå‰∫é2022Âπ¥11ÊúàÂèëÂ∏ÉÔºå‰∏§‰∏™ÊúàÂÜÖÁî®Êà∑Á™ÅÁ†¥1‰∫ø„ÄÇÂÆÉ‰ΩøÁî®RLHFÊäÄÊúØËøõË°åÂØπÈΩêËÆ≠ÁªÉ„ÄÇ...\n"
                                                  ]
                                        },
                                        {
                                                  "data": {
                                                            "text/plain": [
                                                                      "[{'document': 'RLHF (Reinforcement Learning from Human Feedback) ‰ΩøÁî®‰∫∫Á±ªÂèçÈ¶àÊù•‰ºòÂåñÊ®°Âûã„ÄÇÊµÅÁ®ãÂåÖÊã¨Ôºö1)ËÆ≠ÁªÉReward Model 2)‰ΩøÁî®PPO‰ºòÂåñÁ≠ñÁï•Ê®°Âûã„ÄÇ',\n",
                                                                      "  'score': 0.47592031955718994,\n",
                                                                      "  'metadata': {'topic': 'training', 'id': 8}},\n",
                                                                      " {'document': 'LLaMAÊòØMetaÂºÄÂèëÁöÑÂºÄÊ∫êÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁ≥ªÂàó„ÄÇLLaMA 2Êúâ7B„ÄÅ13B„ÄÅ70B‰∏â‰∏™ÁâàÊú¨ÔºåÊîØÊåÅÂïÜ‰∏ö‰ΩøÁî®„ÄÇLLaMA 3Ëøõ‰∏ÄÊ≠•ÊèêÂçá‰∫ÜÊÄßËÉΩ„ÄÇ',\n",
                                                                      "  'score': 0.39844903349876404,\n",
                                                                      "  'metadata': {'topic': 'models', 'id': 4}},\n",
                                                                      " {'document': 'ChatGPTÊòØÂü∫‰∫éGPT-3.5ÂíåGPT-4ÁöÑÂØπËØùAIÔºå‰∫é2022Âπ¥11ÊúàÂèëÂ∏ÉÔºå‰∏§‰∏™ÊúàÂÜÖÁî®Êà∑Á™ÅÁ†¥1‰∫ø„ÄÇÂÆÉ‰ΩøÁî®RLHFÊäÄÊúØËøõË°åÂØπÈΩêËÆ≠ÁªÉ„ÄÇ',\n",
                                                                      "  'score': 0.38481268286705017,\n",
                                                                      "  'metadata': {'topic': 'models', 'id': 5}}]"
                                                            ]
                                                  },
                                                  "execution_count": 9,
                                                  "metadata": {},
                                                  "output_type": "execute_result"
                                        }
                              ],
                              "source": [
                                        "# Ëã±ÊñáÊü•ËØ¢‰πüÂèØ‰ª•\n",
                                        "pretty_search(\"What is RLHF and how does it work?\")"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "id": "rag-header",
                              "metadata": {},
                              "source": [
                                        "---\n",
                                        "\n",
                                        "## 3. ÊûÑÂª∫ÂÆåÊï¥ RAG Á≥ªÁªü"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 10,
                              "id": "rag-class",
                              "metadata": {},
                              "outputs": [
                                        {
                                                  "name": "stdout",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "\n",
                                                            "‚úì RAG Á≥ªÁªüÂàõÂª∫ÊàêÂäü!\n"
                                                  ]
                                        }
                              ],
                              "source": [
                                        "class RAGSystem:\n",
                                        "    \"\"\"\n",
                                        "    ÂÆåÊï¥ÁöÑ RAG Á≥ªÁªü\n",
                                        "    \n",
                                        "    ÁªÑ‰ª∂:\n",
                                        "    - Embedding Model: ÊñáÊú¨ÂêëÈáèÂåñ\n",
                                        "    - Vector Store: Â≠òÂÇ®ÂíåÊ£ÄÁ¥¢ÂêëÈáè\n",
                                        "    - LLM: ÁîüÊàêÂõûÁ≠î\n",
                                        "    \"\"\"\n",
                                        "    \n",
                                        "    SYSTEM_PROMPT = \"\"\"‰Ω†ÊòØ‰∏Ä‰∏™Áü•ËØÜÈóÆÁ≠îÂä©Êâã„ÄÇËØ∑Âü∫‰∫éÊèê‰æõÁöÑÂèÇËÄÉËµÑÊñôÂõûÁ≠îÁî®Êà∑ÈóÆÈ¢ò„ÄÇ\n",
                                        "\n",
                                        "ËßÑÂàô:\n",
                                        "1. Âè™‰ΩøÁî®ÂèÇËÄÉËµÑÊñô‰∏≠ÁöÑ‰ø°ÊÅØÂõûÁ≠î\n",
                                        "2. Â¶ÇÊûúÂèÇËÄÉËµÑÊñô‰∏≠Ê≤°ÊúâÁõ∏ÂÖ≥‰ø°ÊÅØÔºåËØ∑ÊòéÁ°ÆËØ¥Êòé\n",
                                        "3. ÂºïÁî®ÂÖ∑‰ΩìÂÜÖÂÆπÊó∂ËØ∑ÂáÜÁ°Æ\n",
                                        "4. ÂõûÁ≠îË¶ÅÁÆÄÊ¥ÅÂáÜÁ°Æ\n",
                                        "\n",
                                        "ÂèÇËÄÉËµÑÊñô:\n",
                                        "{context}\n",
                                        "\"\"\"\n",
                                        "    \n",
                                        "    def __init__(self, vector_store: SimpleVectorStore, llm):\n",
                                        "        self.vector_store = vector_store\n",
                                        "        self.llm = llm\n",
                                        "    \n",
                                        "    def retrieve(self, query: str, top_k: int = 3) -> List[Dict]:\n",
                                        "        \"\"\"Ê£ÄÁ¥¢Áõ∏ÂÖ≥ÊñáÊ°£\"\"\"\n",
                                        "        return self.vector_store.search(query, top_k=top_k)\n",
                                        "    \n",
                                        "    def format_context(self, results: List[Dict]) -> str:\n",
                                        "        \"\"\"Ê†ºÂºèÂåñÊ£ÄÁ¥¢ÁªìÊûú‰∏∫‰∏ä‰∏ãÊñá\"\"\"\n",
                                        "        context_parts = []\n",
                                        "        for i, result in enumerate(results, 1):\n",
                                        "            context_parts.append(f\"[ÊñáÊ°£{i}] {result['document']}\")\n",
                                        "        return \"\\n\\n\".join(context_parts)\n",
                                        "    \n",
                                        "    def answer(self, question: str, top_k: int = 3, verbose: bool = True) -> str:\n",
                                        "        \"\"\"\n",
                                        "        RAG ÂÆåÊï¥ÊµÅÁ®ãÔºöÊ£ÄÁ¥¢ + ÁîüÊàê\n",
                                        "        \n",
                                        "        Args:\n",
                                        "            question: Áî®Êà∑ÈóÆÈ¢ò\n",
                                        "            top_k: Ê£ÄÁ¥¢ÊñáÊ°£Êï∞Èáè\n",
                                        "            verbose: ÊòØÂê¶ÊòæÁ§∫ËØ¶ÁªÜËøáÁ®ã\n",
                                        "            \n",
                                        "        Returns:\n",
                                        "            str: ÁîüÊàêÁöÑÂõûÁ≠î\n",
                                        "        \"\"\"\n",
                                        "        if verbose:\n",
                                        "            print(f\"\\n{'='*60}\")\n",
                                        "            print(f\"ü§î ÈóÆÈ¢ò: {question}\")\n",
                                        "            print(f\"{'='*60}\")\n",
                                        "        \n",
                                        "        # Step 1: Ê£ÄÁ¥¢\n",
                                        "        if verbose:\n",
                                        "            print(f\"\\nüìö Step 1: Ê£ÄÁ¥¢Áõ∏ÂÖ≥ÊñáÊ°£...\")\n",
                                        "        \n",
                                        "        results = self.retrieve(question, top_k)\n",
                                        "        \n",
                                        "        if verbose:\n",
                                        "            print(f\"ÊâæÂà∞ {len(results)} ‰∏™Áõ∏ÂÖ≥ÊñáÊ°£:\")\n",
                                        "            for i, r in enumerate(results, 1):\n",
                                        "                print(f\"  {i}. [{r['score']:.3f}] {r['document'][:50]}...\")\n",
                                        "        \n",
                                        "        if not results:\n",
                                        "            return \"Êä±Ê≠âÔºåÊ≤°ÊúâÊâæÂà∞Áõ∏ÂÖ≥‰ø°ÊÅØ„ÄÇ\"\n",
                                        "        \n",
                                        "        # Step 2: ÊûÑÂª∫ Prompt\n",
                                        "        context = self.format_context(results)\n",
                                        "        system_prompt = self.SYSTEM_PROMPT.format(context=context)\n",
                                        "        \n",
                                        "        if verbose:\n",
                                        "            print(f\"\\nüìù Step 2: ÊûÑÂª∫ Prompt...\")\n",
                                        "            print(f\"‰∏ä‰∏ãÊñáÈïøÂ∫¶: {len(context)} Â≠óÁ¨¶\")\n",
                                        "        \n",
                                        "        # Step 3: LLM ÁîüÊàêÂõûÁ≠î\n",
                                        "        if verbose:\n",
                                        "            print(f\"\\nü§ñ Step 3: LLM ÁîüÊàêÂõûÁ≠î...\")\n",
                                        "        \n",
                                        "        if self.llm is None:\n",
                                        "            # Ê≤°Êúâ LLMÔºåËøîÂõûÊ£ÄÁ¥¢ÁªìÊûúÊëòË¶Å\n",
                                        "            answer = f\"[Ê£ÄÁ¥¢ÁªìÊûúÊëòË¶Å]\\nÂü∫‰∫éÊ£ÄÁ¥¢Âà∞ÁöÑÊñáÊ°£:\\n{context}\"\n",
                                        "        else:\n",
                                        "            messages = [\n",
                                        "                {\"role\": \"system\", \"content\": system_prompt},\n",
                                        "                {\"role\": \"user\", \"content\": question}\n",
                                        "            ]\n",
                                        "            answer = self.llm.chat(messages, temperature=0.3)\n",
                                        "        \n",
                                        "        if verbose:\n",
                                        "            print(f\"\\n‚úÖ ÂõûÁ≠î:\\n{answer}\")\n",
                                        "        \n",
                                        "        return answer\n",
                                        "    \n",
                                        "    def answer_with_sources(self, question: str, top_k: int = 3) -> Dict:\n",
                                        "        \"\"\"\n",
                                        "        Â∏¶Êù•Ê∫êÁöÑÂõûÁ≠î\n",
                                        "        \n",
                                        "        Returns:\n",
                                        "            dict: {\"answer\": str, \"sources\": List[Dict]}\n",
                                        "        \"\"\"\n",
                                        "        results = self.retrieve(question, top_k)\n",
                                        "        \n",
                                        "        if not results:\n",
                                        "            return {\n",
                                        "                \"answer\": \"Êä±Ê≠âÔºåÊ≤°ÊúâÊâæÂà∞Áõ∏ÂÖ≥‰ø°ÊÅØ„ÄÇ\",\n",
                                        "                \"sources\": []\n",
                                        "            }\n",
                                        "        \n",
                                        "        context = self.format_context(results)\n",
                                        "        system_prompt = self.SYSTEM_PROMPT.format(context=context)\n",
                                        "        \n",
                                        "        if self.llm:\n",
                                        "            messages = [\n",
                                        "                {\"role\": \"system\", \"content\": system_prompt},\n",
                                        "                {\"role\": \"user\", \"content\": question}\n",
                                        "            ]\n",
                                        "            answer = self.llm.chat(messages, temperature=0.3)\n",
                                        "        else:\n",
                                        "            answer = results[0][\"document\"]\n",
                                        "        \n",
                                        "        return {\n",
                                        "            \"answer\": answer,\n",
                                        "            \"sources\": [\n",
                                        "                {\n",
                                        "                    \"content\": r[\"document\"],\n",
                                        "                    \"score\": r[\"score\"],\n",
                                        "                    \"metadata\": r[\"metadata\"]\n",
                                        "                }\n",
                                        "                for r in results\n",
                                        "            ]\n",
                                        "        }\n",
                                        "\n",
                                        "# ÂàõÂª∫ RAG Á≥ªÁªü\n",
                                        "rag = RAGSystem(vector_store, llm)\n",
                                        "print(\"\\n‚úì RAG Á≥ªÁªüÂàõÂª∫ÊàêÂäü!\")"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "id": "test-rag-header",
                              "metadata": {},
                              "source": [
                                        "---\n",
                                        "\n",
                                        "## 4. ÊµãËØï RAG Á≥ªÁªü"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 11,
                              "id": "test-rag-1",
                              "metadata": {},
                              "outputs": [
                                        {
                                                  "name": "stdout",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "\n",
                                                            "============================================================\n",
                                                            "ü§î ÈóÆÈ¢ò: ‰ªÄ‰πàÊòØ TransformerÔºüÂÆÉÊúâ‰ªÄ‰πàÁâπÁÇπÔºü\n",
                                                            "============================================================\n",
                                                            "\n",
                                                            "üìö Step 1: Ê£ÄÁ¥¢Áõ∏ÂÖ≥ÊñáÊ°£...\n",
                                                            "ÊâæÂà∞ 3 ‰∏™Áõ∏ÂÖ≥ÊñáÊ°£:\n",
                                                            "  1. [0.558] TransformerÊòØ2017Âπ¥GoogleÂú®ËÆ∫Êñá'Attention is All You Ne...\n",
                                                            "  2. [0.526] BERT (Bidirectional Encoder Representations from T...\n",
                                                            "  3. [0.377] GPT (Generative Pre-trained Transformer) ÊòØOpenAIÂºÄÂèë...\n",
                                                            "\n",
                                                            "üìù Step 2: ÊûÑÂª∫ Prompt...\n",
                                                            "‰∏ä‰∏ãÊñáÈïøÂ∫¶: 327 Â≠óÁ¨¶\n",
                                                            "\n",
                                                            "ü§ñ Step 3: LLM ÁîüÊàêÂõûÁ≠î...\n",
                                                            "\n",
                                                            "‚úÖ ÂõûÁ≠î:\n",
                                                            "TransformerÊòØ2017Âπ¥GoogleÂú®ËÆ∫Êñá'Attention is All You Need'‰∏≠ÊèêÂá∫ÁöÑÊ∑±Â∫¶Â≠¶‰π†Êû∂ÊûÑ„ÄÇÂÆÉÂºïÂÖ•‰∫ÜËá™Ê≥®ÊÑèÂäõÊú∫Âà∂ÔºåËÉΩÂ§üÂπ∂Ë°åÂ§ÑÁêÜÂ∫èÂàóÊï∞ÊçÆÔºåÊàê‰∏∫Áé∞‰ª£Â§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÂü∫Á°Ä„ÄÇ\n"
                                                  ]
                                        },
                                        {
                                                  "data": {
                                                            "text/plain": [
                                                                      "\"TransformerÊòØ2017Âπ¥GoogleÂú®ËÆ∫Êñá'Attention is All You Need'‰∏≠ÊèêÂá∫ÁöÑÊ∑±Â∫¶Â≠¶‰π†Êû∂ÊûÑ„ÄÇÂÆÉÂºïÂÖ•‰∫ÜËá™Ê≥®ÊÑèÂäõÊú∫Âà∂ÔºåËÉΩÂ§üÂπ∂Ë°åÂ§ÑÁêÜÂ∫èÂàóÊï∞ÊçÆÔºåÊàê‰∏∫Áé∞‰ª£Â§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÂü∫Á°Ä„ÄÇ\""
                                                            ]
                                                  },
                                                  "execution_count": 11,
                                                  "metadata": {},
                                                  "output_type": "execute_result"
                                        }
                              ],
                              "source": [
                                        "# ÊµãËØï 1: Âü∫Á°ÄÈóÆÁ≠î\n",
                                        "rag.answer(\"‰ªÄ‰πàÊòØ TransformerÔºüÂÆÉÊúâ‰ªÄ‰πàÁâπÁÇπÔºü\")"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 12,
                              "id": "test-rag-2",
                              "metadata": {},
                              "outputs": [
                                        {
                                                  "name": "stdout",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "\n",
                                                            "============================================================\n",
                                                            "ü§î ÈóÆÈ¢ò: Â¶Ç‰ΩïËÆ© Base Model ÂèòÊàê Chat ModelÔºü\n",
                                                            "============================================================\n",
                                                            "\n",
                                                            "üìö Step 1: Ê£ÄÁ¥¢Áõ∏ÂÖ≥ÊñáÊ°£...\n",
                                                            "ÊâæÂà∞ 3 ‰∏™Áõ∏ÂÖ≥ÊñáÊ°£:\n",
                                                            "  1. [0.426] SFT (Supervised Fine-Tuning) ÊòØÁõëÁù£ÂæÆË∞ÉÔºå‰ΩøÁî®È´òË¥®ÈáèÁöÑÊåá‰ª§-ÂõûÁ≠îÂØπËÆ≠ÁªÉÊ®°...\n",
                                                            "  2. [0.424] ChatGPTÊòØÂü∫‰∫éGPT-3.5ÂíåGPT-4ÁöÑÂØπËØùAIÔºå‰∫é2022Âπ¥11ÊúàÂèëÂ∏ÉÔºå‰∏§‰∏™ÊúàÂÜÖÁî®Êà∑Á™ÅÁ†¥1...\n",
                                                            "  3. [0.400] Ëá™Ê≥®ÊÑèÂäõÊú∫Âà∂(Self-Attention)ËÆ©Ê®°ÂûãËÉΩÂ§üÂÖ≥Ê≥®ËæìÂÖ•Â∫èÂàó‰∏≠ÁöÑ‰∏çÂêå‰ΩçÁΩÆÔºåÈÄöËøáQ„ÄÅK„ÄÅVÁü©ÈòµËÆ°...\n",
                                                            "\n",
                                                            "üìù Step 2: ÊûÑÂª∫ Prompt...\n",
                                                            "‰∏ä‰∏ãÊñáÈïøÂ∫¶: 250 Â≠óÁ¨¶\n",
                                                            "\n",
                                                            "ü§ñ Step 3: LLM ÁîüÊàêÂõûÁ≠î...\n",
                                                            "\n",
                                                            "‚úÖ ÂõûÁ≠î:\n",
                                                            "Ê†πÊçÆÂèÇËÄÉËµÑÊñôÔºåSFT (Supervised Fine-Tuning) ÊòØÊääBase ModelÂèòÊàêChat ModelÁöÑÂÖ≥ÈîÆÊ≠•È™§„ÄÇÂÆÉ‰ΩøÁî®È´òË¥®ÈáèÁöÑÊåá‰ª§-ÂõûÁ≠îÂØπËÆ≠ÁªÉÊ®°ÂûãÔºåËÆ©Ê®°ÂûãÂ≠¶‰ºöÈÅµÂæ™Êåá‰ª§„ÄÇ\n"
                                                  ]
                                        },
                                        {
                                                  "data": {
                                                            "text/plain": [
                                                                      "'Ê†πÊçÆÂèÇËÄÉËµÑÊñôÔºåSFT (Supervised Fine-Tuning) ÊòØÊääBase ModelÂèòÊàêChat ModelÁöÑÂÖ≥ÈîÆÊ≠•È™§„ÄÇÂÆÉ‰ΩøÁî®È´òË¥®ÈáèÁöÑÊåá‰ª§-ÂõûÁ≠îÂØπËÆ≠ÁªÉÊ®°ÂûãÔºåËÆ©Ê®°ÂûãÂ≠¶‰ºöÈÅµÂæ™Êåá‰ª§„ÄÇ'"
                                                            ]
                                                  },
                                                  "execution_count": 12,
                                                  "metadata": {},
                                                  "output_type": "execute_result"
                                        }
                              ],
                              "source": [
                                        "# ÊµãËØï 2: ËÆ≠ÁªÉÁõ∏ÂÖ≥\n",
                                        "rag.answer(\"Â¶Ç‰ΩïËÆ© Base Model ÂèòÊàê Chat ModelÔºü\")"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 13,
                              "id": "test-rag-3",
                              "metadata": {},
                              "outputs": [
                                        {
                                                  "name": "stdout",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "\n",
                                                            "============================================================\n",
                                                            "ü§î ÈóÆÈ¢ò: LoRA ÂíåÈáèÂåñÂ¶Ç‰ΩïÂ∏ÆÂä©Èôç‰ΩéÊòæÂ≠òÔºü\n",
                                                            "============================================================\n",
                                                            "\n",
                                                            "üìö Step 1: Ê£ÄÁ¥¢Áõ∏ÂÖ≥ÊñáÊ°£...\n",
                                                            "ÊâæÂà∞ 3 ‰∏™Áõ∏ÂÖ≥ÊñáÊ°£:\n",
                                                            "  1. [0.733] LoRA (Low-Rank Adaptation) ÊòØ‰∏ÄÁßçÂèÇÊï∞È´òÊïàÂæÆË∞ÉÊñπÊ≥ïÔºåÂè™ËÆ≠ÁªÉ‰ΩéÁß©Áü©ÈòµÔºåÂ§ßÂ§ßÂáè...\n",
                                                            "  2. [0.534] ÈáèÂåñ(Quantization)ÈÄöËøáÈôç‰ΩéÂèÇÊï∞Á≤æÂ∫¶(FP16‚ÜíINT8‚ÜíINT4)Êù•ÂáèÂ∞ëÂÜÖÂ≠òÂç†Áî®„ÄÇ4-...\n",
                                                            "  3. [0.385] Ëá™Ê≥®ÊÑèÂäõÊú∫Âà∂(Self-Attention)ËÆ©Ê®°ÂûãËÉΩÂ§üÂÖ≥Ê≥®ËæìÂÖ•Â∫èÂàó‰∏≠ÁöÑ‰∏çÂêå‰ΩçÁΩÆÔºåÈÄöËøáQ„ÄÅK„ÄÅVÁü©ÈòµËÆ°...\n",
                                                            "\n",
                                                            "üìù Step 2: ÊûÑÂª∫ Prompt...\n",
                                                            "‰∏ä‰∏ãÊñáÈïøÂ∫¶: 232 Â≠óÁ¨¶\n",
                                                            "\n",
                                                            "ü§ñ Step 3: LLM ÁîüÊàêÂõûÁ≠î...\n",
                                                            "\n",
                                                            "‚úÖ ÂõûÁ≠î:\n",
                                                            "Ê†πÊçÆÂèÇËÄÉËµÑÊñôÔºö\n",
                                                            "\n",
                                                            "- **LoRA** ÈÄöËøáÂè™ËÆ≠ÁªÉ‰ΩéÁß©Áü©ÈòµÔºåÂ§ßÂ§ßÂáèÂ∞ëÂèØËÆ≠ÁªÉÂèÇÊï∞ÈáèÔºå‰ªéËÄåÈôç‰ΩéÊòæÂ≠òÈúÄÊ±ÇÔºà[ÊñáÊ°£1]Ôºâ„ÄÇ\n",
                                                            "- **ÈáèÂåñ** ÈÄöËøáÈôç‰ΩéÂèÇÊï∞Á≤æÂ∫¶ÔºàÂ¶Ç FP16‚ÜíINT8‚ÜíINT4ÔºâÊù•ÂáèÂ∞ëÂÜÖÂ≠òÂç†Áî®Ôºå‰æãÂ¶Ç 4-bit ÈáèÂåñÂèØ‰ª•ËÆ© 7B Ê®°ÂûãÂè™ÈúÄ 4GB ÊòæÂ≠òÔºà[ÊñáÊ°£2]Ôºâ„ÄÇ\n",
                                                            "\n",
                                                            "‰ª•‰∏äÊú∫Âà∂ÂùáÁõ¥Êé•ÈíàÂØπÊòæÂ≠ò‰ºòÂåñÔºåÁ¨¶ÂêàÂèÇËÄÉËµÑÊñôÊèèËø∞„ÄÇ\n"
                                                  ]
                                        },
                                        {
                                                  "data": {
                                                            "text/plain": [
                                                                      "'Ê†πÊçÆÂèÇËÄÉËµÑÊñôÔºö\\n\\n- **LoRA** ÈÄöËøáÂè™ËÆ≠ÁªÉ‰ΩéÁß©Áü©ÈòµÔºåÂ§ßÂ§ßÂáèÂ∞ëÂèØËÆ≠ÁªÉÂèÇÊï∞ÈáèÔºå‰ªéËÄåÈôç‰ΩéÊòæÂ≠òÈúÄÊ±ÇÔºà[ÊñáÊ°£1]Ôºâ„ÄÇ\\n- **ÈáèÂåñ** ÈÄöËøáÈôç‰ΩéÂèÇÊï∞Á≤æÂ∫¶ÔºàÂ¶Ç FP16‚ÜíINT8‚ÜíINT4ÔºâÊù•ÂáèÂ∞ëÂÜÖÂ≠òÂç†Áî®Ôºå‰æãÂ¶Ç 4-bit ÈáèÂåñÂèØ‰ª•ËÆ© 7B Ê®°ÂûãÂè™ÈúÄ 4GB ÊòæÂ≠òÔºà[ÊñáÊ°£2]Ôºâ„ÄÇ\\n\\n‰ª•‰∏äÊú∫Âà∂ÂùáÁõ¥Êé•ÈíàÂØπÊòæÂ≠ò‰ºòÂåñÔºåÁ¨¶ÂêàÂèÇËÄÉËµÑÊñôÊèèËø∞„ÄÇ'"
                                                            ]
                                                  },
                                                  "execution_count": 13,
                                                  "metadata": {},
                                                  "output_type": "execute_result"
                                        }
                              ],
                              "source": [
                                        "# ÊµãËØï 3: ÊäÄÊúØÁªÜËäÇ\n",
                                        "rag.answer(\"LoRA ÂíåÈáèÂåñÂ¶Ç‰ΩïÂ∏ÆÂä©Èôç‰ΩéÊòæÂ≠òÔºü\")"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 14,
                              "id": "test-rag-4",
                              "metadata": {},
                              "outputs": [
                                        {
                                                  "name": "stdout",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "\n",
                                                            "üìù ÂõûÁ≠î: Ê†πÊçÆÂèÇËÄÉËµÑÊñôÔºö  \n",
                                                            "- **RLHF**ÔºàReinforcement Learning from Human FeedbackÔºâÁöÑÊµÅÁ®ãÂåÖÊã¨ÔºöÂÖàËÆ≠ÁªÉReward ModelÔºåÂÜç‰ΩøÁî®PPO‰ºòÂåñÁ≠ñÁï•Ê®°Âûã„ÄÇ  \n",
                                                            "- **DPO**ÔºàDirect Preference OptimizationÔºâÁõ¥Êé•‰ªéÂÅèÂ•ΩÊï∞ÊçÆÂ≠¶‰π†Ôºå‰∏çÈúÄË¶ÅËÆ≠ÁªÉÂçïÁã¨ÁöÑReward ModelÔºåËÆ≠ÁªÉÊõ¥Á®≥ÂÆö„ÄÇ  \n",
                                                            "\n",
                                                            "**‰∏ªË¶ÅÂå∫Âà´**ÔºöRLHFÈúÄË¶ÅÈ¢ùÂ§ñËÆ≠ÁªÉReward ModelÂíåPPO‰ºòÂåñÊ≠•È™§ÔºåËÄåDPOÁúÅÂéª‰∫ÜËÆ≠ÁªÉReward ModelÁöÑÁéØËäÇÔºåÁÆÄÂåñ‰∫ÜÊµÅÁ®ãÂπ∂ÊèêÂçá‰∫ÜËÆ≠ÁªÉÁ®≥ÂÆöÊÄß„ÄÇ\n",
                                                            "\n",
                                                            "üìö Êù•Ê∫ê:\n",
                                                            "  1. [0.479] DPO (Direct Preference Optimization) ÊòØ‰∏ÄÁßçÁÆÄÂåñÁöÑÂØπÈΩêÊñπÊ≥ïÔºåÁõ¥Êé•‰ªéÂÅèÂ•ΩÊï∞ÊçÆÂ≠¶‰π†Ôºå‰∏çÈúÄË¶ÅËÆ≠ÁªÉÂçïÁã¨ÁöÑReward ModelÔºåËÆ≠...\n",
                                                            "  2. [0.413] RLHF (Reinforcement Learning from Human Feedback) ‰ΩøÁî®‰∫∫Á±ªÂèçÈ¶àÊù•‰ºòÂåñÊ®°Âûã„ÄÇÊµÅÁ®ãÂåÖÊã¨Ôºö1)ËÆ≠ÁªÉReward Mo...\n",
                                                            "  3. [0.381] LLaMAÊòØMetaÂºÄÂèëÁöÑÂºÄÊ∫êÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁ≥ªÂàó„ÄÇLLaMA 2Êúâ7B„ÄÅ13B„ÄÅ70B‰∏â‰∏™ÁâàÊú¨ÔºåÊîØÊåÅÂïÜ‰∏ö‰ΩøÁî®„ÄÇLLaMA 3Ëøõ‰∏ÄÊ≠•ÊèêÂçá‰∫ÜÊÄßËÉΩ„ÄÇ...\n"
                                                  ]
                                        }
                              ],
                              "source": [
                                        "# ÊµãËØï 4: Â∏¶Êù•Ê∫êÁöÑÂõûÁ≠î\n",
                                        "result = rag.answer_with_sources(\"RLHF Âíå DPO Êúâ‰ªÄ‰πàÂå∫Âà´Ôºü\")\n",
                                        "print(f\"\\nüìù ÂõûÁ≠î: {result['answer']}\")\n",
                                        "print(f\"\\nüìö Êù•Ê∫ê:\")\n",
                                        "for i, source in enumerate(result['sources'], 1):\n",
                                        "    print(f\"  {i}. [{source['score']:.3f}] {source['content'][:80]}...\")"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 15,
                              "id": "test-rag-5",
                              "metadata": {},
                              "outputs": [
                                        {
                                                  "name": "stdout",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "\n",
                                                            "============================================================\n",
                                                            "ü§î ÈóÆÈ¢ò: Python ÁöÑ GIL ÊòØ‰ªÄ‰πàÔºü\n",
                                                            "============================================================\n",
                                                            "\n",
                                                            "üìö Step 1: Ê£ÄÁ¥¢Áõ∏ÂÖ≥ÊñáÊ°£...\n",
                                                            "ÊâæÂà∞ 3 ‰∏™Áõ∏ÂÖ≥ÊñáÊ°£:\n",
                                                            "  1. [0.358] GPT (Generative Pre-trained Transformer) ÊòØOpenAIÂºÄÂèë...\n",
                                                            "  2. [0.316] ChatGPTÊòØÂü∫‰∫éGPT-3.5ÂíåGPT-4ÁöÑÂØπËØùAIÔºå‰∫é2022Âπ¥11ÊúàÂèëÂ∏ÉÔºå‰∏§‰∏™ÊúàÂÜÖÁî®Êà∑Á™ÅÁ†¥1...\n",
                                                            "  3. [0.248] KV CacheÊòØÊé®ÁêÜÂä†ÈÄüÊäÄÊúØÔºåÁºìÂ≠òÂ∑≤ËÆ°ÁÆóÁöÑKeyÂíåValueÁü©ÈòµÔºåÈÅøÂÖçÈáçÂ§çËÆ°ÁÆóÔºåÂèØ‰ª•ÊòæËëóÊèêÂçáËá™ÂõûÂΩí...\n",
                                                            "\n",
                                                            "üìù Step 2: ÊûÑÂª∫ Prompt...\n",
                                                            "‰∏ä‰∏ãÊñáÈïøÂ∫¶: 240 Â≠óÁ¨¶\n",
                                                            "\n",
                                                            "ü§ñ Step 3: LLM ÁîüÊàêÂõûÁ≠î...\n",
                                                            "\n",
                                                            "‚úÖ ÂõûÁ≠î:\n",
                                                            "ÂèÇËÄÉËµÑÊñô‰∏≠Ê≤°ÊúâÊèê‰æõPython GILÁöÑÁõ∏ÂÖ≥‰ø°ÊÅØ„ÄÇÊèê‰æõÁöÑÂèÇËÄÉËµÑÊñô‰ªÖÊ∂âÂèäGPTÊ®°ÂûãÁ≥ªÂàó„ÄÅChatGPTÂíåKV CacheÁ≠âAIÊäÄÊúØÂÜÖÂÆπÔºå‰∏éPythonÁºñÁ®ã‰∏≠ÁöÑGILÔºàGlobal Interpreter LockÔºâÊó†ÂÖ≥„ÄÇ\n"
                                                  ]
                                        },
                                        {
                                                  "data": {
                                                            "text/plain": [
                                                                      "'ÂèÇËÄÉËµÑÊñô‰∏≠Ê≤°ÊúâÊèê‰æõPython GILÁöÑÁõ∏ÂÖ≥‰ø°ÊÅØ„ÄÇÊèê‰æõÁöÑÂèÇËÄÉËµÑÊñô‰ªÖÊ∂âÂèäGPTÊ®°ÂûãÁ≥ªÂàó„ÄÅChatGPTÂíåKV CacheÁ≠âAIÊäÄÊúØÂÜÖÂÆπÔºå‰∏éPythonÁºñÁ®ã‰∏≠ÁöÑGILÔºàGlobal Interpreter LockÔºâÊó†ÂÖ≥„ÄÇ'"
                                                            ]
                                                  },
                                                  "execution_count": 15,
                                                  "metadata": {},
                                                  "output_type": "execute_result"
                                        }
                              ],
                              "source": [
                                        "# ÊµãËØï 5: Áü•ËØÜÂ∫ì‰∏≠‰∏çÂ≠òÂú®ÁöÑÈóÆÈ¢ò\n",
                                        "rag.answer(\"Python ÁöÑ GIL ÊòØ‰ªÄ‰πàÔºü\")"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "id": "advanced-header",
                              "metadata": {},
                              "source": [
                                        "---\n",
                                        "\n",
                                        "## 5. È´òÁ∫ßÂäüËÉΩÔºöÊñáÊ°£ÂàÜÂùó‰∏éÈáçÊéíÂ∫è"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 16,
                              "id": "chunking",
                              "metadata": {},
                              "outputs": [
                                        {
                                                  "name": "stdout",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "ÂéüÊñáÈïøÂ∫¶: 257 Â≠óÁ¨¶\n",
                                                            "ÂàÜÊàê 2 ‰∏™Âùó:\n",
                                                            "\n",
                                                            "Âùó 1 (181 Â≠óÁ¨¶):\n",
                                                            "  Â§ßËØ≠Ë®ÄÊ®°Âûã(Large Language Model, LLM)ÊòØÊåáÂèÇÊï∞ÈáèÂ∑®Â§ßÁöÑËØ≠Ë®ÄÊ®°Âûã„ÄÇ\n",
                                                            "Ëøô‰∫õÊ®°ÂûãÈÄöÂ∏∏Âü∫‰∫éTransformerÊû∂ÊûÑÔºåÈÄöËøáÂú®Êµ∑ÈáèÊñáÊú¨Êï∞ÊçÆ‰∏äËøõË°åÈ¢ÑËÆ≠ÁªÉÊù•Â≠¶‰π†ËØ≠Ë®ÄÁöÑÁªüËÆ°ËßÑÂæã„ÄÇ\n",
                                                            "È¢ÑËÆ≠ÁªÉÂÆåÊàê...\n",
                                                            "\n",
                                                            "Âùó 2 (104 Â≠óÁ¨¶):\n",
                                                            "  RLHF(Âü∫‰∫é‰∫∫Á±ªÂèçÈ¶àÁöÑÂº∫ÂåñÂ≠¶‰π†)ÂíåDPO(Áõ¥Êé•ÂÅèÂ•Ω‰ºòÂåñ)„ÄÇ\n",
                                                            "‰∏∫‰∫ÜÈôç‰ΩéÂæÆË∞ÉÁöÑËÆ°ÁÆóÊàêÊú¨ÔºåÁ†îÁ©∂‰∫∫ÂëòÊèêÂá∫‰∫ÜLoRAÁ≠âÂèÇÊï∞È´òÊïàÂæÆË∞ÉÊñπÊ≥ï„ÄÇ\n",
                                                            "Âú®Êé®ÁêÜÈò∂ÊÆµÔºåKV CacheÊäÄÊúØÂèØ‰ª•Âä†ÈÄüËá™ÂõûÂΩíÁîüÊàêÔºåÈáèÂåñÊäÄÊúØÂèØ‰ª•ÂáèÂ∞ëÂÜÖ...\n"
                                                  ]
                                        }
                              ],
                              "source": [
                                        "class DocumentChunker:\n",
                                        "    \"\"\"\n",
                                        "    ÊñáÊ°£ÂàÜÂùóÂô®\n",
                                        "    \n",
                                        "    ÈïøÊñáÊ°£ÈúÄË¶ÅÂàÜÊàêÂ∞èÂùóÊâçËÉΩÊúâÊïàÊ£ÄÁ¥¢\n",
                                        "    \"\"\"\n",
                                        "    \n",
                                        "    def __init__(self, chunk_size: int = 500, chunk_overlap: int = 50):\n",
                                        "        self.chunk_size = chunk_size\n",
                                        "        self.chunk_overlap = chunk_overlap\n",
                                        "    \n",
                                        "    def chunk_text(self, text: str, metadata: Dict = None) -> List[Dict]:\n",
                                        "        \"\"\"\n",
                                        "        Â∞ÜÊñáÊú¨ÂàÜÊàêÈáçÂè†ÁöÑÂ∞èÂùó\n",
                                        "        \n",
                                        "        Args:\n",
                                        "            text: ÂéüÂßãÊñáÊú¨\n",
                                        "            metadata: ÂÖÉÊï∞ÊçÆ\n",
                                        "            \n",
                                        "        Returns:\n",
                                        "            List[Dict]: [{\"text\": str, \"metadata\": dict}, ...]\n",
                                        "        \"\"\"\n",
                                        "        if metadata is None:\n",
                                        "            metadata = {}\n",
                                        "        \n",
                                        "        chunks = []\n",
                                        "        start = 0\n",
                                        "        chunk_id = 0\n",
                                        "        \n",
                                        "        while start < len(text):\n",
                                        "            end = start + self.chunk_size\n",
                                        "            \n",
                                        "            # Â∞ùËØïÂú®Âè•Â≠êËæπÁïåÂàÜÂâ≤\n",
                                        "            if end < len(text):\n",
                                        "                # ÂØªÊâæÊúÄËøëÁöÑÂè•Âè∑\n",
                                        "                for punct in ['„ÄÇ', '.', 'ÔºÅ', '!', 'Ôºü', '?', '\\n']:\n",
                                        "                    last_punct = text[start:end].rfind(punct)\n",
                                        "                    if last_punct > self.chunk_size // 2:\n",
                                        "                        end = start + last_punct + 1\n",
                                        "                        break\n",
                                        "            \n",
                                        "            chunk_text = text[start:end].strip()\n",
                                        "            if chunk_text:\n",
                                        "                chunk_metadata = {\n",
                                        "                    **metadata,\n",
                                        "                    \"chunk_id\": chunk_id,\n",
                                        "                    \"start\": start,\n",
                                        "                    \"end\": end\n",
                                        "                }\n",
                                        "                chunks.append({\n",
                                        "                    \"text\": chunk_text,\n",
                                        "                    \"metadata\": chunk_metadata\n",
                                        "                })\n",
                                        "                chunk_id += 1\n",
                                        "            \n",
                                        "            start = end - self.chunk_overlap\n",
                                        "        \n",
                                        "        return chunks\n",
                                        "    \n",
                                        "    def chunk_documents(self, documents: List[str], metadatas: List[Dict] = None) -> Tuple[List[str], List[Dict]]:\n",
                                        "        \"\"\"\n",
                                        "        ÊâπÈáèÂàÜÂùóÊñáÊ°£\n",
                                        "        \n",
                                        "        Returns:\n",
                                        "            (texts, metadatas)\n",
                                        "        \"\"\"\n",
                                        "        if metadatas is None:\n",
                                        "            metadatas = [{} for _ in documents]\n",
                                        "        \n",
                                        "        all_texts = []\n",
                                        "        all_metadata = []\n",
                                        "        \n",
                                        "        for doc, meta in zip(documents, metadatas):\n",
                                        "            chunks = self.chunk_text(doc, meta)\n",
                                        "            for chunk in chunks:\n",
                                        "                all_texts.append(chunk[\"text\"])\n",
                                        "                all_metadata.append(chunk[\"metadata\"])\n",
                                        "        \n",
                                        "        return all_texts, all_metadata\n",
                                        "\n",
                                        "# ÊµãËØïÂàÜÂùó\n",
                                        "chunker = DocumentChunker(chunk_size=200, chunk_overlap=30)\n",
                                        "\n",
                                        "long_doc = \"\"\"\n",
                                        "Â§ßËØ≠Ë®ÄÊ®°Âûã(Large Language Model, LLM)ÊòØÊåáÂèÇÊï∞ÈáèÂ∑®Â§ßÁöÑËØ≠Ë®ÄÊ®°Âûã„ÄÇ\n",
                                        "Ëøô‰∫õÊ®°ÂûãÈÄöÂ∏∏Âü∫‰∫éTransformerÊû∂ÊûÑÔºåÈÄöËøáÂú®Êµ∑ÈáèÊñáÊú¨Êï∞ÊçÆ‰∏äËøõË°åÈ¢ÑËÆ≠ÁªÉÊù•Â≠¶‰π†ËØ≠Ë®ÄÁöÑÁªüËÆ°ËßÑÂæã„ÄÇ\n",
                                        "È¢ÑËÆ≠ÁªÉÂÆåÊàêÂêéÔºåÊ®°ÂûãÂèØ‰ª•ÈÄöËøáÂæÆË∞É(Fine-tuning)Êù•ÈÄÇÂ∫îÁâπÂÆö‰ªªÂä°„ÄÇ\n",
                                        "Â∏∏ËßÅÁöÑÂæÆË∞ÉÊñπÊ≥ïÂåÖÊã¨SFT(ÁõëÁù£ÂæÆË∞É)„ÄÅRLHF(Âü∫‰∫é‰∫∫Á±ªÂèçÈ¶àÁöÑÂº∫ÂåñÂ≠¶‰π†)ÂíåDPO(Áõ¥Êé•ÂÅèÂ•Ω‰ºòÂåñ)„ÄÇ\n",
                                        "‰∏∫‰∫ÜÈôç‰ΩéÂæÆË∞ÉÁöÑËÆ°ÁÆóÊàêÊú¨ÔºåÁ†îÁ©∂‰∫∫ÂëòÊèêÂá∫‰∫ÜLoRAÁ≠âÂèÇÊï∞È´òÊïàÂæÆË∞ÉÊñπÊ≥ï„ÄÇ\n",
                                        "Âú®Êé®ÁêÜÈò∂ÊÆµÔºåKV CacheÊäÄÊúØÂèØ‰ª•Âä†ÈÄüËá™ÂõûÂΩíÁîüÊàêÔºåÈáèÂåñÊäÄÊúØÂèØ‰ª•ÂáèÂ∞ëÂÜÖÂ≠òÂç†Áî®„ÄÇ\n",
                                        "\"\"\"\n",
                                        "\n",
                                        "chunks = chunker.chunk_text(long_doc, {\"source\": \"intro\"})\n",
                                        "print(f\"ÂéüÊñáÈïøÂ∫¶: {len(long_doc)} Â≠óÁ¨¶\")\n",
                                        "print(f\"ÂàÜÊàê {len(chunks)} ‰∏™Âùó:\")\n",
                                        "for i, chunk in enumerate(chunks):\n",
                                        "    print(f\"\\nÂùó {i+1} ({len(chunk['text'])} Â≠óÁ¨¶):\")\n",
                                        "    print(f\"  {chunk['text'][:100]}...\")"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "id": "summary",
                              "metadata": {},
                              "source": [
                                        "---\n",
                                        "\n",
                                        "## Êú¨ËäÇÊÄªÁªì\n",
                                        "\n",
                                        "\n",
                                        "1. **ÁúüÂÆûÁöÑ Embedding Ê®°Âûã**\n",
                                        "   - SentenceTransformers ÁîüÊàêËØ≠‰πâÂêëÈáè\n",
                                        "   - ÊîØÊåÅÂ§öËØ≠Ë®ÄÊ£ÄÁ¥¢\n",
                                        "\n",
                                        "2. **ÂêëÈáèÊï∞ÊçÆÂ∫ì**\n",
                                        "   - ‰ΩôÂº¶Áõ∏‰ººÂ∫¶ÊêúÁ¥¢\n",
                                        "   - ÂÖÉÊï∞ÊçÆËøáÊª§\n",
                                        "   - ÊåÅ‰πÖÂåñÂ≠òÂÇ®\n",
                                        "\n",
                                        "3. **RAG ÂÆåÊï¥ÊµÅÁ®ã**\n",
                                        "   - Ê£ÄÁ¥¢ ‚Üí ÈáçÊéí ‚Üí ÁîüÊàê\n",
                                        "   - Â∏¶Êù•Ê∫êÁöÑÂõûÁ≠î\n",
                                        "\n",
                                        "### Êâ©Â±ïÁªÉ‰π†\n",
                                        "\n",
                                        "1. **Ê∑ªÂä† PDF Ëß£Êûê**: ‰ΩøÁî® PyPDF2 Âä†ËΩΩ PDF ÊñáÊ°£\n",
                                        "2. **Êé•ÂÖ• ChromaDB**: ‰ΩøÁî®‰∏ì‰∏öÁöÑÂêëÈáèÊï∞ÊçÆÂ∫ì\n",
                                        "3. **ÂÆûÁé∞Ê∑∑ÂêàÊ£ÄÁ¥¢**: ÁªìÂêàÂÖ≥ÈîÆËØçÂíåËØ≠‰πâÊêúÁ¥¢"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 19,
                              "id": "exercise",
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "# ÁªÉ‰π†: Ê∑ªÂä†‰ªéÊñá‰ª∂Âä†ËΩΩÊñáÊ°£ÁöÑÂäüËÉΩ\n",
                                        "\n",
                                        "def load_text_file(file_path: str) -> str:\n",
                                        "    \"\"\"Âä†ËΩΩÊñáÊú¨Êñá‰ª∂\"\"\"\n",
                                        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
                                        "        return f.read()\n",
                                        "\n",
                                        "def load_markdown_file(file_path: str) -> List[str]:\n",
                                        "    \"\"\"Âä†ËΩΩ Markdown Êñá‰ª∂ÔºåÊåâÊ†áÈ¢òÂàÜÂâ≤\"\"\"\n",
                                        "    import re\n",
                                        "    content = load_text_file(file_path)\n",
                                        "    \n",
                                        "    # Êåâ ## Ê†áÈ¢òÂàÜÂâ≤\n",
                                        "    sections = re.split(r'\\n## ', content)\n",
                                        "    return [s.strip() for s in sections if s.strip()]\n",
                                        "\n",
                                        "# Á§∫‰æãÁî®Ê≥ï (ÈúÄË¶ÅÂÆûÈôÖÊñá‰ª∂)\n",
                                        "# docs = load_markdown_file('knowledge_base.md')\n",
                                        "# vector_store.add_documents(docs)\n",
                                        "\n",
                                        "#print(\"‚úì ÊñáÊ°£Âä†ËΩΩÂô®Â∑≤ÂÆö‰πâ\")"
                              ]
                    }
          ],
          "metadata": {
                    "kernelspec": {
                              "display_name": "llmc",
                              "language": "python",
                              "name": "python3"
                    },
                    "language_info": {
                              "codemirror_mode": {
                                        "name": "ipython",
                                        "version": 3
                              },
                              "file_extension": ".py",
                              "mimetype": "text/x-python",
                              "name": "python",
                              "nbconvert_exporter": "python",
                              "pygments_lexer": "ipython3",
                              "version": "3.9.25"
                    }
          },
          "nbformat": 4,
          "nbformat_minor": 5
}
