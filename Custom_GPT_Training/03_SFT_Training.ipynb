{
          "cells": [
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "# 自建GPT训练流程 - Part 3: SFT指令微调\n",
                                        "\n",
                                        "## 概述\n",
                                        "\n",
                                        "本notebook演示如何对预训练模型进行**SFT (Supervised Fine-Tuning)**，让模型学会遵循用户指令。\n",
                                        "\n",
                                        "**设备建议：** CPU 可跑（训练时间更长），GPU 可加速。\n",
                                        "\n",
                                        "### 预训练 vs SFT 的区别\n",
                                        "\n",
                                        "```\n",
                                        "预训练:\n",
                                        "  输入: \"机器学习是人工智能\"\n",
                                        "  目标: 预测下一个token（续写）\n",
                                        "\n",
                                        "SFT:\n",
                                        "  输入: \"<|user|>什么是机器学习？<|assistant|>\"\n",
                                        "  目标: 生成高质量回答，只对assistant部分计算loss\n",
                                        "```\n",
                                        "\n",
                                        "### SFT的核心技术点\n",
                                        "\n",
                                        "1. **ChatML格式**: 标准化的对话模板\n",
                                        "2. **Loss Masking**: 只对assistant回答部分计算loss\n",
                                        "3. **指令多样性**: 多种类型的指令和回答\n",
                                        "4. **数据质量**: 高质量的示例回答"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "## 环境设置"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "import torch\n",
                                        "import torch.nn as nn\n",
                                        "import torch.nn.functional as F\n",
                                        "from torch.utils.data import Dataset, DataLoader\n",
                                        "import numpy as np\n",
                                        "import matplotlib.pyplot as plt\n",
                                        "from tqdm.auto import tqdm\n",
                                        "import os\n",
                                        "import sys\n",
                                        "import json\n",
                                        "import copy\n",
                                        "\n",
                                        "# 兼容从项目根目录或本目录运行\n",
                                        "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\")) if os.path.basename(os.getcwd()) == \"Custom_GPT_Training\" else os.getcwd()\n",
                                        "CUSTOM_GPT_DIR = os.path.join(PROJECT_ROOT, \"Custom_GPT_Training\")\n",
                                        "sys.path.insert(0, CUSTOM_GPT_DIR)\n",
                                        "\n",
                                        "from custom_gpt import (\n",
                                        "    CustomGPT, \n",
                                        "    GPTConfig, \n",
                                        "    SimpleTokenizer,\n",
                                        "    count_parameters\n",
                                        ")\n",
                                        "\n",
                                        "# 设备选择\n",
                                        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                                        "print(f\"使用设备: {device}\")\n",
                                        "\n",
                                        "# 可复现性\n",
                                        "torch.manual_seed(42)\n",
                                        "np.random.seed(42)"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "## Part 1: SFT训练数据\n",
                                        "\n",
                                        "本路线聚焦“短知识问答”，方便观察指令理解与回答质量。\n",
                                        "\n",
                                        "输出：简洁、单句的事实性回答。\n"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "# SFT训练数据：从 data/ 读取（训练/验证/测试拆分）\n",
                                        "import json\n",
                                        "from pathlib import Path\n",
                                        "\n",
                                        "def resolve_data_dir():\n",
                                        "    candidates = [Path.cwd(), Path.cwd().parent]\n",
                                        "    for base in candidates:\n",
                                        "        data_dir = base / \"data\"\n",
                                        "        if data_dir.exists():\n",
                                        "            return str(data_dir)\n",
                                        "    return os.path.join(os.getcwd(), \"data\")\n",
                                        "\n",
                                        "DATA_DIR = resolve_data_dir()\n",
                                        "\n",
                                        "\n",
                                        "def load_jsonl(path):\n",
                                        "    with open(path, \"r\", encoding=\"utf-8-sig\") as f:\n",
                                        "        return [json.loads(line) for line in f if line.strip()]\n",
                                        "\n",
                                        "SFT_DATA = load_jsonl(os.path.join(DATA_DIR, \"custom_sft_train.jsonl\"))\n",
                                        "VAL_DATA = load_jsonl(os.path.join(DATA_DIR, \"custom_sft_val.jsonl\"))\n",
                                        "TEST_DATA = load_jsonl(os.path.join(DATA_DIR, \"custom_sft_test.jsonl\"))\n",
                                        "\n",
                                        "print(f\"训练集: {len(SFT_DATA)} 条 | 验证集: {len(VAL_DATA)} 条 | 测试集: {len(TEST_DATA)} 条\")\n",
                                        "print(f\"任务类型: {sorted(set(t['category'] for t in SFT_DATA))}\")\n",
                                        "print(f\"示例: {SFT_DATA[0]}\")\n"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "## Part 2: ChatML格式化"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "class ChatMLFormatter:\n",
                                        "    \"\"\"\n",
                                        "    ChatML格式化器\n",
                                        "    \n",
                                        "    将(指令, 回答)转换为标准ChatML格式:\n",
                                        "    <|system|>你是一个有帮助的AI助手。<|endoftext|>\n",
                                        "    <|user|>用户指令<|endoftext|>\n",
                                        "    <|assistant|>模型回答<|endoftext|>\n",
                                        "    \"\"\"\n",
                                        "    \n",
                                        "    SYSTEM_PROMPT = \"你是一个有帮助的AI助手。\"\n",
                                        "    \n",
                                        "    # 特殊token\n",
                                        "    SYSTEM_TOKEN = \"<|system|>\"\n",
                                        "    USER_TOKEN = \"<|user|>\"\n",
                                        "    ASSISTANT_TOKEN = \"<|assistant|>\"\n",
                                        "    END_TOKEN = \"<|endoftext|>\"\n",
                                        "    \n",
                                        "    @classmethod\n",
                                        "    def format(cls, instruction, response, include_system=True):\n",
                                        "        \"\"\"格式化单条数据\"\"\"\n",
                                        "        parts = []\n",
                                        "        \n",
                                        "        if include_system:\n",
                                        "            parts.append(f\"{cls.SYSTEM_TOKEN}{cls.SYSTEM_PROMPT}{cls.END_TOKEN}\")\n",
                                        "        \n",
                                        "        parts.append(f\"{cls.USER_TOKEN}{instruction}{cls.END_TOKEN}\")\n",
                                        "        parts.append(f\"{cls.ASSISTANT_TOKEN}{response}{cls.END_TOKEN}\")\n",
                                        "        \n",
                                        "        return \"\\n\".join(parts)\n",
                                        "    \n",
                                        "    @classmethod\n",
                                        "    def format_prompt_only(cls, instruction, include_system=True):\n",
                                        "        \"\"\"只格式化prompt（用于推理）\"\"\"\n",
                                        "        parts = []\n",
                                        "        \n",
                                        "        if include_system:\n",
                                        "            parts.append(f\"{cls.SYSTEM_TOKEN}{cls.SYSTEM_PROMPT}{cls.END_TOKEN}\")\n",
                                        "        \n",
                                        "        parts.append(f\"{cls.USER_TOKEN}{instruction}{cls.END_TOKEN}\")\n",
                                        "        parts.append(f\"{cls.ASSISTANT_TOKEN}\")  # 等待模型续写\n",
                                        "        \n",
                                        "        return \"\\n\".join(parts)\n",
                                        "\n",
                                        "# 示例\n",
                                        "sample = SFT_DATA[0]\n",
                                        "formatted = ChatMLFormatter.format(sample['instruction'], sample['response'])\n",
                                        "print(\"ChatML格式示例:\")\n",
                                        "print(\"=\" * 50)\n",
                                        "print(formatted)"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "## Part 3: SFT数据集（带Loss Masking）"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "class SFTDataset(Dataset):\n",
                                        "    \"\"\"\n",
                                        "    SFT数据集\n",
                                        "    \n",
                                        "    关键: 只对assistant回答部分计算loss\n",
                                        "    \n",
                                        "    通过设置labels中非assistant部分为-100，\n",
                                        "    CrossEntropyLoss会自动忽略这些位置。\n",
                                        "    \"\"\"\n",
                                        "    \n",
                                        "    def __init__(self, data, tokenizer, max_length=256):\n",
                                        "        self.tokenizer = tokenizer\n",
                                        "        self.max_length = max_length\n",
                                        "        self.data = data\n",
                                        "        \n",
                                        "        # 字符级分词器会直接处理ChatML标记；仅在word模式时扩充词表\n",
                                        "        if getattr(tokenizer, \"mode\", \"char\") != \"char\" and hasattr(tokenizer, \"add_special_token\"):\n",
                                        "            special_tokens = [\n",
                                        "                ChatMLFormatter.SYSTEM_TOKEN,\n",
                                        "                ChatMLFormatter.USER_TOKEN,\n",
                                        "                ChatMLFormatter.ASSISTANT_TOKEN,\n",
                                        "                ChatMLFormatter.END_TOKEN\n",
                                        "            ]\n",
                                        "            for token in special_tokens:\n",
                                        "                if token not in tokenizer.token_to_id:\n",
                                        "                    tokenizer.add_special_token(token)\n",
                                        "        \n",
                                        "        print(f\"SFT数据集: {len(data)} 条\")\n",
                                        "        print(f\"最大长度: {max_length}\")\n",
                                        "    \n",
                                        "    def __len__(self):\n",
                                        "        return len(self.data)\n",
                                        "    \n",
                                        "    def __getitem__(self, idx):\n",
                                        "        item = self.data[idx]\n",
                                        "        \n",
                                        "        # 格式化\n",
                                        "        full_text = ChatMLFormatter.format(\n",
                                        "            item['instruction'], \n",
                                        "            item['response']\n",
                                        "        )\n",
                                        "        \n",
                                        "        # 编码完整文本\n",
                                        "        full_ids = self.tokenizer.encode(full_text, add_bos=True, add_eos=False)\n",
                                        "        \n",
                                        "        # 找到assistant回答开始的位置\n",
                                        "        # 编码到assistant token为止的部分\n",
                                        "        prompt_text = ChatMLFormatter.format_prompt_only(item['instruction'])\n",
                                        "        prompt_ids = self.tokenizer.encode(prompt_text, add_bos=True, add_eos=False)\n",
                                        "        assistant_start = len(prompt_ids)\n",
                                        "        \n",
                                        "        # 截断或填充\n",
                                        "        if len(full_ids) > self.max_length:\n",
                                        "            full_ids = full_ids[:self.max_length]\n",
                                        "            assistant_start = min(assistant_start, self.max_length)\n",
                                        "        \n",
                                        "        # 创建labels（只对assistant部分计算loss）\n",
                                        "        labels = [-100] * len(full_ids)  # -100会被CrossEntropyLoss忽略\n",
                                        "        for i in range(assistant_start, len(full_ids)):\n",
                                        "            labels[i] = full_ids[i]  # 只有assistant部分有label\n",
                                        "        \n",
                                        "        # 填充\n",
                                        "        pad_len = self.max_length - len(full_ids)\n",
                                        "        if pad_len > 0:\n",
                                        "            full_ids = full_ids + [self.tokenizer.pad_token_id] * pad_len\n",
                                        "            labels = labels + [-100] * pad_len  # padding部分也忽略\n",
                                        "        \n",
                                        "        # 创建attention mask\n",
                                        "        attention_mask = [1 if id != self.tokenizer.pad_token_id else 0 for id in full_ids]\n",
                                        "        \n",
                                        "        return {\n",
                                        "            'input_ids': torch.tensor(full_ids[:-1], dtype=torch.long),  # 输入不含最后一个\n",
                                        "            'labels': torch.tensor(labels[1:], dtype=torch.long),  # label右移一位\n",
                                        "            'attention_mask': torch.tensor(attention_mask[:-1], dtype=torch.float)\n",
                                        "        }"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "# 加载预训练的tokenizer和模型\n",
                                        "CHECKPOINT_DIR = os.path.join(PROJECT_ROOT, \"models\", \"custom_gpt\")\n",
                                        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
                                        "\n",
                                        "# 加载tokenizer（优先使用预训练构建的词表）\n",
                                        "tokenizer_path = os.path.join(CHECKPOINT_DIR, \"tokenizer.pkl\")\n",
                                        "if os.path.exists(tokenizer_path):\n",
                                        "    tokenizer = SimpleTokenizer.load(tokenizer_path)\n",
                                        "    print(f\"加载tokenizer, 词表大小: {len(tokenizer)}\")\n",
                                        "else:\n",
                                        "    print(\"未找到预训练tokenizer，使用SFT数据构建新词表...\")\n",
                                        "    tokenizer = SimpleTokenizer(vocab_size=5000, mode=\"char\", min_freq=1)\n",
                                        "    tokenizer.build_vocab([\n",
                                        "        record[\"instruction\"] + \" \" + record[\"response\"] for record in SFT_DATA\n",
                                        "    ])\n",
                                        "    tokenizer.save(tokenizer_path)\n",
                                        "    print(f\"新词表已保存, 词表大小: {len(tokenizer)}\")\n",
                                        "\n",
                                        "# 创建SFT数据集\n",
                                        "MAX_LENGTH = 256\n",
                                        "BATCH_SIZE = 8\n",
                                        "\n",
                                        "train_dataset = SFTDataset(SFT_DATA, tokenizer, max_length=MAX_LENGTH)\n",
                                        "val_dataset = SFTDataset(VAL_DATA, tokenizer, max_length=MAX_LENGTH)\n",
                                        "\n",
                                        "print(f\"\\n训练集: {len(train_dataset)} 样本\")\n",
                                        "print(f\"验证集: {len(val_dataset)} 样本\")\n",
                                        "\n",
                                        "# DataLoader\n",
                                        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
                                        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "# 可视化Loss Masking\n",
                                        "sample = train_dataset[0]\n",
                                        "\n",
                                        "print(\"Loss Masking可视化:\")\n",
                                        "print(\"=\" * 60)\n",
                                        "\n",
                                        "input_ids = sample['input_ids'].tolist()\n",
                                        "labels = sample['labels'].tolist()\n",
                                        "\n",
                                        "# 显示前50个token\n",
                                        "print(\"\\nToken ID | Label | 是否计算Loss\")\n",
                                        "print(\"-\" * 40)\n",
                                        "for i in range(min(50, len(input_ids))):\n",
                                        "    token = tokenizer.decode([input_ids[i]], skip_special=False)\n",
                                        "    label = labels[i]\n",
                                        "    compute_loss = \"✓\" if label != -100 else \"✗\"\n",
                                        "    print(f\"{input_ids[i]:6d} | {label:6} | {compute_loss}  '{token[:10]}'\")\n",
                                        "\n",
                                        "print(f\"\\n总token数: {len(input_ids)}\")\n",
                                        "print(f\"计算loss的token数: {sum(1 for l in labels if l != -100)}\")"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "## Part 4: SFT Trainer"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "class SFTTrainer:\n",
                                        "    \"\"\"\n",
                                        "    SFT Trainer\n",
                                        "    \n",
                                        "    与预训练Trainer的区别:\n",
                                        "    1. 使用带masking的labels\n",
                                        "    2. 通常使用较小的学习率\n",
                                        "    3. 训练轮次较少\n",
                                        "    \"\"\"\n",
                                        "    \n",
                                        "    def __init__(\n",
                                        "        self,\n",
                                        "        model,\n",
                                        "        train_loader,\n",
                                        "        val_loader,\n",
                                        "        lr=5e-5,  # SFT通常用较小学习率\n",
                                        "        weight_decay=0.01,\n",
                                        "        warmup_steps=50,\n",
                                        "        max_grad_norm=1.0,\n",
                                        "        device='cpu'\n",
                                        "    ):\n",
                                        "        self.model = model.to(device)\n",
                                        "        self.train_loader = train_loader\n",
                                        "        self.val_loader = val_loader\n",
                                        "        self.device = device\n",
                                        "        self.max_grad_norm = max_grad_norm\n",
                                        "        self.warmup_steps = warmup_steps\n",
                                        "        self.base_lr = lr\n",
                                        "        \n",
                                        "        # 优化器\n",
                                        "        self.optimizer = torch.optim.AdamW(\n",
                                        "            model.parameters(),\n",
                                        "            lr=lr,\n",
                                        "            weight_decay=weight_decay\n",
                                        "        )\n",
                                        "        \n",
                                        "        # 训练历史\n",
                                        "        self.train_losses = []\n",
                                        "        self.val_losses = []\n",
                                        "        self.global_step = 0\n",
                                        "    \n",
                                        "    def get_lr(self, step, total_steps):\n",
                                        "        \"\"\"学习率调度\"\"\"\n",
                                        "        if step < self.warmup_steps:\n",
                                        "            return self.base_lr * step / self.warmup_steps\n",
                                        "        else:\n",
                                        "            progress = (step - self.warmup_steps) / (total_steps - self.warmup_steps)\n",
                                        "            return self.base_lr * 0.5 * (1 + np.cos(np.pi * progress))\n",
                                        "    \n",
                                        "    def compute_loss(self, logits, labels):\n",
                                        "        \"\"\"\n",
                                        "        计算loss（只对非-100的位置）\n",
                                        "        \n",
                                        "        CrossEntropyLoss默认ignore_index=-100\n",
                                        "        \"\"\"\n",
                                        "        loss_fn = nn.CrossEntropyLoss(ignore_index=-100)\n",
                                        "        \n",
                                        "        # Reshape: (batch, seq, vocab) -> (batch*seq, vocab)\n",
                                        "        logits_flat = logits.view(-1, logits.size(-1))\n",
                                        "        labels_flat = labels.view(-1)\n",
                                        "        \n",
                                        "        return loss_fn(logits_flat, labels_flat)\n",
                                        "    \n",
                                        "    def train_epoch(self, epoch, total_epochs):\n",
                                        "        \"\"\"训练一个epoch\"\"\"\n",
                                        "        self.model.train()\n",
                                        "        total_loss = 0\n",
                                        "        total_steps = len(self.train_loader) * total_epochs\n",
                                        "        \n",
                                        "        pbar = tqdm(self.train_loader, desc=f\"Epoch {epoch+1}/{total_epochs}\")\n",
                                        "        for batch in pbar:\n",
                                        "            # 更新学习率\n",
                                        "            lr = self.get_lr(self.global_step, total_steps)\n",
                                        "            for param_group in self.optimizer.param_groups:\n",
                                        "                param_group['lr'] = lr\n",
                                        "            \n",
                                        "            # 准备数据\n",
                                        "            input_ids = batch['input_ids'].to(self.device)\n",
                                        "            labels = batch['labels'].to(self.device)\n",
                                        "            attention_mask = batch['attention_mask'].to(self.device)\n",
                                        "            \n",
                                        "            # 前向传播\n",
                                        "            outputs = self.model(input_ids, attention_mask=attention_mask)\n",
                                        "            logits = outputs['logits']\n",
                                        "            \n",
                                        "            # 计算loss（只对assistant部分）\n",
                                        "            loss = self.compute_loss(logits, labels)\n",
                                        "            \n",
                                        "            # 反向传播\n",
                                        "            self.optimizer.zero_grad()\n",
                                        "            loss.backward()\n",
                                        "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)\n",
                                        "            self.optimizer.step()\n",
                                        "            \n",
                                        "            # 记录\n",
                                        "            total_loss += loss.item()\n",
                                        "            self.train_losses.append(loss.item())\n",
                                        "            self.global_step += 1\n",
                                        "            \n",
                                        "            pbar.set_postfix({'loss': f\"{loss.item():.4f}\", 'lr': f\"{lr:.2e}\"})\n",
                                        "        \n",
                                        "        return total_loss / len(self.train_loader)\n",
                                        "    \n",
                                        "    @torch.no_grad()\n",
                                        "    def evaluate(self):\n",
                                        "        \"\"\"验证集评估\"\"\"\n",
                                        "        self.model.eval()\n",
                                        "        total_loss = 0\n",
                                        "        \n",
                                        "        for batch in self.val_loader:\n",
                                        "            input_ids = batch['input_ids'].to(self.device)\n",
                                        "            labels = batch['labels'].to(self.device)\n",
                                        "            attention_mask = batch['attention_mask'].to(self.device)\n",
                                        "            \n",
                                        "            outputs = self.model(input_ids, attention_mask=attention_mask)\n",
                                        "            loss = self.compute_loss(outputs['logits'], labels)\n",
                                        "            total_loss += loss.item()\n",
                                        "        \n",
                                        "        avg_loss = total_loss / len(self.val_loader)\n",
                                        "        self.val_losses.append(avg_loss)\n",
                                        "        return avg_loss\n",
                                        "    \n",
                                        "    def train(self, epochs, save_dir=None):\n",
                                        "        \"\"\"完整训练流程\"\"\"\n",
                                        "        print(f\"\\n开始SFT训练\")\n",
                                        "        print(f\"{'='*50}\")\n",
                                        "        print(f\"  模型参数: {count_parameters(self.model)}\")\n",
                                        "        print(f\"  训练样本: {len(self.train_loader.dataset)}\")\n",
                                        "        print(f\"  Epochs: {epochs}\")\n",
                                        "        print(f\"{'='*50}\\n\")\n",
                                        "        \n",
                                        "        best_val_loss = float('inf')\n",
                                        "        \n",
                                        "        for epoch in range(epochs):\n",
                                        "            train_loss = self.train_epoch(epoch, epochs)\n",
                                        "            val_loss = self.evaluate()\n",
                                        "            \n",
                                        "            print(f\"\\nEpoch {epoch+1}/{epochs}:\")\n",
                                        "            print(f\"  训练Loss: {train_loss:.4f}\")\n",
                                        "            print(f\"  验证Loss: {val_loss:.4f}\")\n",
                                        "            \n",
                                        "            if save_dir and val_loss < best_val_loss:\n",
                                        "                best_val_loss = val_loss\n",
                                        "                self.model.save_pretrained(os.path.join(save_dir, \"sft_model\"))\n",
                                        "                print(f\"  ✓ 保存最佳模型\")\n",
                                        "        \n",
                                        "        return {'train_losses': self.train_losses, 'val_losses': self.val_losses}"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "## Part 5: 执行SFT训练"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "# 加载预训练模型\n",
                                        "pretrained_path = os.path.join(CHECKPOINT_DIR, \"pretrained_model\")\n",
                                        "\n",
                                        "if os.path.exists(pretrained_path):\n",
                                        "    print(\"加载预训练模型...\")\n",
                                        "    model = CustomGPT.from_pretrained(pretrained_path)\n",
                                        "else:\n",
                                        "    print(\"预训练模型不存在，创建新模型...\")\n",
                                        "    config = GPTConfig(\n",
                                        "        vocab_size=len(tokenizer),\n",
                                        "        max_seq_len=MAX_LENGTH,\n",
                                        "        d_model=384,\n",
                                        "        n_heads=6,\n",
                                        "        n_layers=6,\n",
                                        "        d_ff=1536\n",
                                        "    )\n",
                                        "    model = CustomGPT(config)\n",
                                        "\n",
                                        "print(f\"模型参数: {count_parameters(model)}\")"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "# 创建Trainer\n",
                                        "trainer = SFTTrainer(\n",
                                        "    model=model,\n",
                                        "    train_loader=train_loader,\n",
                                        "    val_loader=val_loader,\n",
                                        "    lr=5e-5,  # SFT用较小学习率\n",
                                        "    weight_decay=0.01,\n",
                                        "    warmup_steps=20,\n",
                                        "    device=device\n",
                                        ")\n",
                                        "\n",
                                        "# 执行训练\n",
                                        "EPOCHS = 5\n",
                                        "history = trainer.train(epochs=EPOCHS, save_dir=CHECKPOINT_DIR)"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "# 可视化训练过程\n",
                                        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
                                        "\n",
                                        "# 训练Loss\n",
                                        "axes[0].plot(history['train_losses'], 'b-', alpha=0.5)\n",
                                        "window = 20\n",
                                        "if len(history['train_losses']) > window:\n",
                                        "    smoothed = np.convolve(history['train_losses'], np.ones(window)/window, mode='valid')\n",
                                        "    axes[0].plot(range(window-1, len(history['train_losses'])), smoothed, 'r-', linewidth=2)\n",
                                        "axes[0].set_xlabel('Step')\n",
                                        "axes[0].set_ylabel('Loss')\n",
                                        "axes[0].set_title('SFT Training Loss')\n",
                                        "axes[0].grid(True, alpha=0.3)\n",
                                        "\n",
                                        "# 验证Loss\n",
                                        "axes[1].plot(history['val_losses'], 'g-o', linewidth=2)\n",
                                        "axes[1].set_xlabel('Epoch')\n",
                                        "axes[1].set_ylabel('Loss')\n",
                                        "axes[1].set_title('SFT Val Loss')\n",
                                        "axes[1].grid(True, alpha=0.3)\n",
                                        "\n",
                                        "plt.tight_layout()\n",
                                        "plt.show()"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "## Part 6: 测试SFT模型"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "def chat(model, tokenizer, instruction, max_new_tokens=100, temperature=0.2):\n",
                                        "    \"\"\"\n",
                                        "    与SFT模型对话\n",
                                        "    \"\"\"\n",
                                        "    model.eval()\n",
                                        "    \n",
                                        "    # 格式化prompt\n",
                                        "    prompt = ChatMLFormatter.format_prompt_only(instruction)\n",
                                        "    input_ids = torch.tensor([tokenizer.encode(prompt, add_bos=True, add_eos=False)]).to(device)\n",
                                        "    \n",
                                        "    # 生成\n",
                                        "    with torch.no_grad():\n",
                                        "        output_ids = model.generate(\n",
                                        "            input_ids,\n",
                                        "            max_new_tokens=max_new_tokens,\n",
                                        "            temperature=temperature,\n",
                                        "            top_k=None,\n",
                                        "            do_sample=False\n",
                                        "        )\n",
                                        "    \n",
                                        "    # 解码\n",
                                        "    full_response = tokenizer.decode(output_ids[0].tolist())\n",
                                        "    \n",
                                        "    # 提取assistant回答部分\n",
                                        "    if ChatMLFormatter.ASSISTANT_TOKEN in full_response:\n",
                                        "        response = full_response.split(ChatMLFormatter.ASSISTANT_TOKEN)[-1]\n",
                                        "        if ChatMLFormatter.END_TOKEN in response:\n",
                                        "            response = response.split(ChatMLFormatter.END_TOKEN)[0]\n",
                                        "    else:\n",
                                        "        response = full_response\n",
                                        "    \n",
                                        "    return response.strip()"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "# 加载SFT模型\n",
                                        "sft_model = CustomGPT.from_pretrained(\n",
                                        "    os.path.join(CHECKPOINT_DIR, \"sft_model\")\n",
                                        ").to(device)\n",
                                        "\n",
                                        "print(\"加载SFT模型完成\")"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "# 测试问答\n",
                                        "test_samples = TEST_DATA[:5]\n",
                                        "\n",
                                        "print(\"SFT模型问答测试(来自测试集):\")\n",
                                        "print(\"=\" * 60)\n",
                                        "\n",
                                        "for item in test_samples:\n",
                                        "    instruction = item[\"instruction\"]\n",
                                        "    expected = item[\"expected\"]\n",
                                        "    response = chat(sft_model, tokenizer, instruction)\n",
                                        "    print(f\"\\n指令: {instruction}\")\n",
                                        "    print(f\"期望: {expected}\")\n",
                                        "    print(f\"输出: {response}\")\n",
                                        "    print(\"-\" * 40)"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "## Part 7: Base模型 vs SFT模型对比"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "# 加载预训练base模型进行对比\n",
                                        "pretrained_path = os.path.join(CHECKPOINT_DIR, \"pretrained_model\")\n",
                                        "if os.path.exists(pretrained_path):\n",
                                        "    base_model = CustomGPT.from_pretrained(pretrained_path).to(device)\n",
                                        "    \n",
                                        "    print(\"Base模型 vs SFT模型对比:\")\n",
                                        "    print(\"=\" * 60)\n",
                                        "    \n",
                                        "    test_instruction = \"用一句话解释：深度学习是什么？\"\n",
                                        "    \n",
                                        "    # Base模型（直接续写，不理解指令）\n",
                                        "    base_model.eval()\n",
                                        "    base_input = torch.tensor([tokenizer.encode(test_instruction, add_bos=True, add_eos=False)]).to(device)\n",
                                        "    with torch.no_grad():\n",
                                        "        base_output = base_model.generate(base_input, max_new_tokens=50, temperature=0.7)\n",
                                        "    base_response = tokenizer.decode(base_output[0].tolist())\n",
                                        "    \n",
                                        "    # SFT模型（理解指令，生成回答）\n",
                                        "    sft_response = chat(sft_model, tokenizer, test_instruction)\n",
                                        "    \n",
                                        "    print(f\"\\n指令: {test_instruction}\")\n",
                                        "    print(f\"\\n[Base模型] (直接续写):\")\n",
                                        "    print(f\"{base_response}\")\n",
                                        "    print(f\"\\n[SFT模型] (理解指令):\")\n",
                                        "    print(f\"{sft_response}\")\n",
                                        "else:\n",
                                        "    print(\"Base模型不存在，跳过对比\")"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "## 总结\n",
                                        "\n",
                                        "### 本notebook完成的内容\n",
                                        "\n",
                                        "1. **ChatML格式化**\n",
                                        "   - 标准化对话模板\n",
                                        "   - 区分system/user/assistant角色\n",
                                        "\n",
                                        "2. **SFT数据集**\n",
                                        "   - (指令, 回答)对\n",
                                        "   - **Loss Masking**: 只对assistant部分计算loss\n",
                                        "   - 通过设置labels=-100忽略非目标token\n",
                                        "\n",
                                        "3. **SFT训练**\n",
                                        "   - 较小学习率(5e-5)\n",
                                        "   - 较少训练轮次\n",
                                        "   - 从预训练模型初始化\n",
                                        "\n",
                                        "### SFT后模型的变化\n",
                                        "\n",
                                        "- **之前**: 只会续写文本，不理解指令\n",
                                        "- **之后**: 理解用户意图，生成针对性回答\n",
                                        "\n",
                                        "### 下一步: DPO训练 (04_DPO_Training.ipynb)\n",
                                        "\n",
                                        "SFT后的模型仍可能生成不够好的回答。DPO让模型学习人类偏好，选择更好的回答方式。"
                              ]
                    }
          ],
          "metadata": {
                    "kernelspec": {
                              "display_name": "llmc",
                              "language": "python",
                              "name": "python3"
                    },
                    "language_info": {
                              "codemirror_mode": {
                                        "name": "ipython",
                                        "version": 3
                              },
                              "file_extension": ".py",
                              "mimetype": "text/x-python",
                              "name": "python",
                              "nbconvert_exporter": "python",
                              "pygments_lexer": "ipython3",
                              "version": "3.9.25"
                    }
          },
          "nbformat": 4,
          "nbformat_minor": 4
}
