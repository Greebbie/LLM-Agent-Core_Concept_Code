{
          "cells": [
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "# 自建GPT训练流程 - Part 5: 评估与对比\n",
                                        "\n",
                                        "## 概述\n",
                                        "\n",
                                        "本notebook对整个训练流程中产生的三个模型进行系统评估和对比：\n",
                                        "\n",
                                        "**设备建议：** CPU 可跑。\n",
                                        "\n",
                                        "```\n",
                                        "Base模型（预训练） → SFT模型（指令微调） → DPO模型（偏好对齐）\n",
                                        "```\n",
                                        "\n",
                                        "### 评估维度\n",
                                        "\n",
                                        "| 维度 | 指标 | 说明 |\n",
                                        "|------|------|------|\n",
                                        "| **语言建模能力** | 困惑度 (Perplexity) | 越低越好 |\n",
                                        "| **指令遵循能力** | 任务准确率 | 短问答可自动评估 |\n",
                                        "| **生成质量** | 流畅度、多样性 | Distinct-n | \n",
                                        "| **偏好一致性** | 选择好回答的比例 | 人类偏好对齐 |\n"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "## 环境设置"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "import torch\n",
                                        "import torch.nn as nn\n",
                                        "import torch.nn.functional as F\n",
                                        "from torch.utils.data import Dataset, DataLoader\n",
                                        "import numpy as np\n",
                                        "import matplotlib.pyplot as plt\n",
                                        "import pandas as pd\n",
                                        "from tqdm.auto import tqdm\n",
                                        "import os\n",
                                        "import sys\n",
                                        "import re\n",
                                        "from collections import Counter\n",
                                        "plt.rcParams[\"font.sans-serif\"] = [\"Microsoft YaHei\", \"SimHei\", \"Noto Sans CJK SC\", \"Arial Unicode MS\"]\n",
                                        "plt.rcParams[\"axes.unicode_minus\"] = False\n",
                                        "\n",
                                        "\n",
                                        "# 兼容从项目根目录或本目录运行\n",
                                        "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\")) if os.path.basename(os.getcwd()) == \"Custom_GPT_Training\" else os.getcwd()\n",
                                        "CUSTOM_GPT_DIR = os.path.join(PROJECT_ROOT, \"Custom_GPT_Training\")\n",
                                        "sys.path.insert(0, CUSTOM_GPT_DIR)\n",
                                        "\n",
                                        "from custom_gpt import (\n",
                                        "    CustomGPT, \n",
                                        "    GPTConfig, \n",
                                        "    SimpleTokenizer,\n",
                                        "    count_parameters\n",
                                        ")\n",
                                        "\n",
                                        "# 设备选择\n",
                                        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                                        "print(f\"使用设备: {device}\")\n",
                                        "\n",
                                        "# 可复现性\n",
                                        "torch.manual_seed(42)\n",
                                        "np.random.seed(42)"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "## Part 1: 加载所有模型"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "CHECKPOINT_DIR = os.path.join(PROJECT_ROOT, \"models\", \"custom_gpt\")\n",
                                        "\n",
                                        "# 加载tokenizer\n",
                                        "tokenizer = SimpleTokenizer.load(os.path.join(CHECKPOINT_DIR, \"tokenizer.pkl\"))\n",
                                        "print(f\"Tokenizer词表大小: {len(tokenizer)}\")\n",
                                        "\n",
                                        "# 加载三个阶段的模型\n",
                                        "models = {}\n",
                                        "\n",
                                        "model_paths = {\n",
                                        "    'Base (预训练)': 'pretrained_model',\n",
                                        "    'SFT (指令微调)': 'sft_model',\n",
                                        "    'DPO (偏好对齐)': 'dpo_model'\n",
                                        "}\n",
                                        "\n",
                                        "print(\"\\n加载模型:\")\n",
                                        "for name, path in model_paths.items():\n",
                                        "    full_path = os.path.join(CHECKPOINT_DIR, path)\n",
                                        "    if os.path.exists(full_path):\n",
                                        "        models[name] = CustomGPT.from_pretrained(full_path).to(device)\n",
                                        "        models[name].eval()\n",
                                        "        print(f\"  ✓ {name}: {count_parameters(models[name])}\")\n",
                                        "    else:\n",
                                        "        print(f\"  ✗ {name}: 不存在\")\n",
                                        "\n",
                                        "print(f\"\\n成功加载 {len(models)} 个模型\")"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "## Part 2: 困惑度评估 (Perplexity)"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "# 评估用测试文本\n",
                                        "TEST_TEXTS = [\n",
                                        "    \"深度学习是机器学习的一个重要分支，使用多层神经网络来学习数据的表示。\",\n",
                                        "    \"Transformer架构通过自注意力机制实现了并行计算，大大提高了训练效率。\",\n",
                                        "    \"预训练语言模型首先在大规模语料上学习通用知识，然后针对具体任务进行微调。\",\n",
                                        "    \"强化学习通过与环境的交互来学习最优策略，智能体通过奖励信号不断改进。\",\n",
                                        "    \"注意力机制让模型能够动态关注输入的不同部分，是现代NLP的核心技术。\",\n",
                                        "    \"梯度下降算法通过计算损失函数对参数的梯度来更新模型参数。\",\n",
                                        "    \"过拟合是模型在训练数据上表现很好但在新数据上表现差的现象。\",\n",
                                        "    \"正则化技术如Dropout和权重衰减可以有效防止模型过拟合。\",\n",
                                        "]\n",
                                        "\n",
                                        "print(f\"测试文本数量: {len(TEST_TEXTS)}\")"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "@torch.no_grad()\n",
                                        "def compute_perplexity(model, tokenizer, texts):\n",
                                        "    \"\"\"\n",
                                        "    计算模型在文本集上的困惑度\n",
                                        "    \n",
                                        "    困惑度 = exp(平均交叉熵损失)\n",
                                        "    \"\"\"\n",
                                        "    model.eval()\n",
                                        "    total_loss = 0\n",
                                        "    total_tokens = 0\n",
                                        "    \n",
                                        "    for text in texts:\n",
                                        "        # 编码\n",
                                        "        ids = tokenizer.encode(text, add_bos=True, add_eos=True)\n",
                                        "        if len(ids) < 2:\n",
                                        "            continue\n",
                                        "        \n",
                                        "        input_ids = torch.tensor([ids[:-1]]).to(device)\n",
                                        "        labels = torch.tensor([ids[1:]]).to(device)\n",
                                        "        \n",
                                        "        # 前向传播\n",
                                        "        outputs = model(input_ids)\n",
                                        "        logits = outputs['logits']\n",
                                        "        \n",
                                        "        # 计算交叉熵\n",
                                        "        loss = F.cross_entropy(\n",
                                        "            logits.view(-1, logits.size(-1)),\n",
                                        "            labels.view(-1),\n",
                                        "            reduction='sum'\n",
                                        "        )\n",
                                        "        \n",
                                        "        total_loss += loss.item()\n",
                                        "        total_tokens += labels.numel()\n",
                                        "    \n",
                                        "    avg_loss = total_loss / total_tokens\n",
                                        "    perplexity = np.exp(avg_loss)\n",
                                        "    \n",
                                        "    return perplexity, avg_loss"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "# 计算各模型的困惑度\n",
                                        "print(\"模型困惑度对比:\")\n",
                                        "print(\"=\" * 50)\n",
                                        "print(\"提示: DPO优化人类偏好，困惑度可能上升，这里仍纳入对比。\")\n",
                                        "\n",
                                        "ppl_results = {}\n",
                                        "\n",
                                        "for name, model in models.items():\n",
                                        "    ppl, loss = compute_perplexity(model, tokenizer, TEST_TEXTS)\n",
                                        "    ppl_results[name] = ppl\n",
                                        "    print(f\"{name}:\")\n",
                                        "    print(f\"  困惑度: {ppl:.2f}\")\n",
                                        "    print(f\"  平均Loss: {loss:.4f}\")\n",
                                        "    print()"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "# 可视化困惑度对比\n",
                                        "if ppl_results:\n",
                                        "    fig, ax = plt.subplots(figsize=(10, 5))\n",
                                        "    \n",
                                        "    names = list(ppl_results.keys())\n",
                                        "    values = list(ppl_results.values())\n",
                                        "    colors = ['#3498db', '#2ecc71', '#9b59b6']\n",
                                        "    \n",
                                        "    bars = ax.bar(names, values, color=colors[:len(names)])\n",
                                        "    \n",
                                        "    # 添加数值标签\n",
                                        "    for bar, val in zip(bars, values):\n",
                                        "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
                                        "                f'{val:.1f}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
                                        "    \n",
                                        "    ax.set_ylabel('困惑度 (Perplexity)', fontsize=12)\n",
                                        "    ax.set_title('困惑度对比', fontsize=14, fontweight='bold')\n",
                                        "    ax.grid(True, alpha=0.3, axis='y')\n",
                                        "    \n",
                                        "    plt.tight_layout()\n",
                                        "    plt.show()\n",
                                        "    \n",
                                        "    print(\"\\n说明: 困惑度越低表示模型对测试文本的预测越准确\")"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "## Part 3: 指令遵循能力评估"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "# ChatML格式化器\n",
                                        "class ChatMLFormatter:\n",
                                        "    SYSTEM_PROMPT = \"你是一个有帮助的AI助手。\"\n",
                                        "    SYSTEM_TOKEN = \"<|system|>\"\n",
                                        "    USER_TOKEN = \"<|user|>\"\n",
                                        "    ASSISTANT_TOKEN = \"<|assistant|>\"\n",
                                        "    END_TOKEN = \"<|endoftext|>\"\n",
                                        "    \n",
                                        "    @classmethod\n",
                                        "    def format_prompt_only(cls, instruction, include_system=True):\n",
                                        "        parts = []\n",
                                        "        if include_system:\n",
                                        "            parts.append(f\"{cls.SYSTEM_TOKEN}{cls.SYSTEM_PROMPT}{cls.END_TOKEN}\")\n",
                                        "        parts.append(f\"{cls.USER_TOKEN}{instruction}{cls.END_TOKEN}\")\n",
                                        "        parts.append(f\"{cls.ASSISTANT_TOKEN}\")\n",
                                        "        return \"\\n\".join(parts)"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "def generate_response(model, tokenizer, instruction, max_new_tokens=80, temperature=0.7, use_chatml=True, do_sample=True):\n",
                                        "    \"\"\"\n",
                                        "    生成回答\n",
                                        "\n",
                                        "    use_chatml=True: 使用ChatML格式（适合SFT/DPO模型）\n",
                                        "    use_chatml=False: 直接续写（适合Base模型）\n",
                                        "    \"\"\"\n",
                                        "    model.eval()\n",
                                        "\n",
                                        "    if use_chatml:\n",
                                        "        prompt = ChatMLFormatter.format_prompt_only(instruction)\n",
                                        "    else:\n",
                                        "        prompt = instruction\n",
                                        "\n",
                                        "    input_ids = torch.tensor([tokenizer.encode(prompt, add_bos=True, add_eos=False)]).to(device)\n",
                                        "\n",
                                        "    with torch.no_grad():\n",
                                        "        output_ids = model.generate(\n",
                                        "            input_ids,\n",
                                        "            max_new_tokens=max_new_tokens,\n",
                                        "            temperature=temperature,\n",
                                        "            top_k=50,\n",
                                        "            do_sample=do_sample\n",
                                        "        )\n",
                                        "\n",
                                        "    full_response = tokenizer.decode(output_ids[0].tolist())\n",
                                        "\n",
                                        "    # 提取回答部分\n",
                                        "    if use_chatml and ChatMLFormatter.ASSISTANT_TOKEN in full_response:\n",
                                        "        response = full_response.split(ChatMLFormatter.ASSISTANT_TOKEN)[-1]\n",
                                        "        if ChatMLFormatter.END_TOKEN in response:\n",
                                        "            response = response.split(ChatMLFormatter.END_TOKEN)[0]\n",
                                        "    else:\n",
                                        "        # 对于Base模型，返回生成的部分\n",
                                        "        prompt_decoded = tokenizer.decode(input_ids[0].tolist())\n",
                                        "        response = full_response[len(prompt_decoded):]\n",
                                        "\n",
                                        "    return response.strip()\n"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "# 评估任务集（从 data/ 读取，保证与训练分离）\n",
                                        "import json\n",
                                        "from pathlib import Path\n",
                                        "\n",
                                        "def resolve_data_dir():\n",
                                        "    candidates = [Path.cwd(), Path.cwd().parent]\n",
                                        "    for base in candidates:\n",
                                        "        data_dir = base / \"data\"\n",
                                        "        if data_dir.exists():\n",
                                        "            return str(data_dir)\n",
                                        "    return os.path.join(os.getcwd(), \"data\")\n",
                                        "\n",
                                        "DATA_DIR = resolve_data_dir()\n",
                                        "\n",
                                        "# 评估速度控制（减小样本数可显著加速）\n",
                                        "MAX_EVAL_TASKS = 200\n",
                                        "MAX_PREFERENCE_TEST = 200\n",
                                        "MAX_DIVERSITY_PROMPTS = 3\n",
                                        "DIVERSITY_SAMPLES_PER_PROMPT = 1\n",
                                        "\n",
                                        "\n",
                                        "def load_jsonl(path):\n",
                                        "    with open(path, \"r\", encoding=\"utf-8-sig\") as f:\n",
                                        "        return [json.loads(line) for line in f if line.strip()]\n",
                                        "\n",
                                        "TEST_TASKS = load_jsonl(os.path.join(DATA_DIR, \"custom_sft_test.jsonl\"))\n",
                                        "PREFERENCE_TEST = load_jsonl(os.path.join(DATA_DIR, \"custom_dpo_test.jsonl\"))\n",
                                        "\n",
                                        "TEST_TASKS = TEST_TASKS[:MAX_EVAL_TASKS]\n",
                                        "PREFERENCE_TEST = PREFERENCE_TEST[:MAX_PREFERENCE_TEST]\n",
                                        "\n",
                                        "print(f\"评估任务数: {len(TEST_TASKS)} | 偏好对数: {len(PREFERENCE_TEST)}\")\n"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "# 对比各模型的回答（可量化评估）\n",
                                        "\n",
                                        "def normalize_text(text):\n",
                                        "    return \" \".join(text.strip().lower().split())\n",
                                        "\n",
                                        "def extract_number(text):\n",
                                        "    match = re.search(r\"-?\\d+\", text)\n",
                                        "    return match.group(0) if match else None\n",
                                        "\n",
                                        "def extract_json(text):\n",
                                        "    candidate = text.strip()\n",
                                        "    if not candidate.startswith('{') or not candidate.endswith('}'):\n",
                                        "        return None\n",
                                        "    try:\n",
                                        "        return json.loads(candidate)\n",
                                        "    except Exception:\n",
                                        "        return None\n",
                                        "\n",
                                        "TEXT_SIM_THRESHOLD = 0.5\n",
                                        "\n",
                                        "def char_f1(a, b):\n",
                                        "    if not a or not b:\n",
                                        "        return 0.0\n",
                                        "    ca = Counter(a)\n",
                                        "    cb = Counter(b)\n",
                                        "    overlap = sum((ca & cb).values())\n",
                                        "    precision = overlap / max(len(b), 1)\n",
                                        "    recall = overlap / max(len(a), 1)\n",
                                        "    if precision + recall == 0:\n",
                                        "        return 0.0\n",
                                        "    return 2 * precision * recall / (precision + recall)\n",
                                        "\n",
                                        "def lcs_ratio(a, b):\n",
                                        "    if not a or not b:\n",
                                        "        return 0.0\n",
                                        "    dp = [0] * (len(b) + 1)\n",
                                        "    for i in range(len(a)):\n",
                                        "        prev = 0\n",
                                        "        for j in range(len(b)):\n",
                                        "            temp = dp[j + 1]\n",
                                        "            if a[i] == b[j]:\n",
                                        "                dp[j + 1] = prev + 1\n",
                                        "            else:\n",
                                        "                dp[j + 1] = max(dp[j + 1], dp[j])\n",
                                        "            prev = temp\n",
                                        "    return dp[-1] / max(len(a), 1)\n",
                                        "\n",
                                        "def bigram_recall(a, b):\n",
                                        "    if not a:\n",
                                        "        return 0.0\n",
                                        "    if len(a) < 2:\n",
                                        "        return 1.0 if a in b else 0.0\n",
                                        "    expected_bigrams = [a[i:i+2] for i in range(len(a) - 1)]\n",
                                        "    pred_bigrams = set(b[i:i+2] for i in range(len(b) - 1)) if len(b) >= 2 else set()\n",
                                        "    hits = sum(1 for bg in expected_bigrams if bg in pred_bigrams)\n",
                                        "    return hits / max(len(expected_bigrams), 1)\n",
                                        "\n",
                                        "def score_prediction(pred, task):\n",
                                        "    pred_norm = normalize_text(pred)\n",
                                        "    expected = task[\"expected\"]\n",
                                        "    expected_norm = normalize_text(expected)\n",
                                        "    metric = task[\"metric\"]\n",
                                        "\n",
                                        "    if metric == \"numeric\":\n",
                                        "        return extract_number(pred_norm) == expected\n",
                                        "\n",
                                        "    if metric == \"json\":\n",
                                        "        pred_obj = extract_json(pred)\n",
                                        "        try:\n",
                                        "            expected_obj = json.loads(expected)\n",
                                        "        except Exception:\n",
                                        "            expected_obj = None\n",
                                        "        return pred_obj == expected_obj\n",
                                        "\n",
                                        "    # 文本任务：允许相似表达（字符级F1 / LCS / bigram recall）\n",
                                        "    if expected_norm in pred_norm:\n",
                                        "        return True\n",
                                        "    f1 = char_f1(expected_norm, pred_norm)\n",
                                        "    lcs = lcs_ratio(expected_norm, pred_norm)\n",
                                        "    recall = bigram_recall(expected_norm, pred_norm)\n",
                                        "    return max(f1, lcs, recall) >= TEXT_SIM_THRESHOLD\n",
                                        "\n",
                                        "def evaluate_instruction_following(model, tasks, use_chatml):\n",
                                        "    results = {}\n",
                                        "    samples = []\n",
                                        "    for task in tasks:\n",
                                        "        pred = generate_response(\n",
                                        "            model,\n",
                                        "            tokenizer,\n",
                                        "            task[\"instruction\"],\n",
                                        "            max_new_tokens=40,\n",
                                        "            temperature=1.0,\n",
                                        "            use_chatml=use_chatml,\n",
                                        "            do_sample=False\n",
                                        "        )\n",
                                        "        correct = score_prediction(pred, task)\n",
                                        "        results.setdefault(task[\"category\"], []).append(correct)\n",
                                        "        if len(samples) < 3:\n",
                                        "            samples.append((task[\"instruction\"], task[\"expected\"], pred))\n",
                                        "\n",
                                        "    summary = {cat: sum(vals) / len(vals) for cat, vals in results.items()}\n",
                                        "    summary[\"overall\"] = sum(sum(v) for v in results.values()) / sum(len(v) for v in results.values())\n",
                                        "    return summary, samples\n",
                                        "\n",
                                        "print(f\"指令遵循能力对比 (文本相似度阈值={TEXT_SIM_THRESHOLD:.2f}, F1/LCS/BigramRecall):\")\n",
                                        "print(\"=\" * 80)\n",
                                        "\n",
                                        "instruction_results = {}\n",
                                        "\n",
                                        "for name, model in models.items():\n",
                                        "    use_chatml = 'Base' not in name\n",
                                        "    summary, samples = evaluate_instruction_following(model, TEST_TASKS, use_chatml)\n",
                                        "    instruction_results[name] = summary\n",
                                        "\n",
                                        "    print(f\"\\n{name}:\")\n",
                                        "    for cat, acc in summary.items():\n",
                                        "        print(f\"  {cat}: {acc*100:.1f}%\" if cat != \"overall\" else f\"  overall: {acc*100:.1f}%\")\n",
                                        "\n",
                                        "    print(\"  示例:\")\n",
                                        "    for ins, exp, pred in samples:\n",
                                        "        print(f\"    Q: {ins}\")\n",
                                        "        print(f\"    Expected: {exp}\")\n",
                                        "        print(f\"    Pred: {pred[:80]}\")\n",
                                        "\n",
                                        "print(\"\\n\" + \"=\" * 80)\n"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "## Part 4: 生成多样性评估"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "def compute_diversity(responses):\n",
                                        "    \"\"\"\n",
                                        "    计算生成多样性\n",
                                        "    \n",
                                        "    使用distinct n-gram比例\n",
                                        "    \"\"\"\n",
                                        "    all_unigrams = []\n",
                                        "    all_bigrams = []\n",
                                        "    \n",
                                        "    for response in responses:\n",
                                        "        tokens = list(response)  # 字符级\n",
                                        "        all_unigrams.extend(tokens)\n",
                                        "        all_bigrams.extend(zip(tokens[:-1], tokens[1:]))\n",
                                        "    \n",
                                        "    if len(all_unigrams) == 0:\n",
                                        "        return 0, 0\n",
                                        "    \n",
                                        "    distinct_1 = len(set(all_unigrams)) / len(all_unigrams)\n",
                                        "    distinct_2 = len(set(all_bigrams)) / len(all_bigrams) if all_bigrams else 0\n",
                                        "    \n",
                                        "    return distinct_1, distinct_2"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "# 为多个问题生成回答评估多样性\n",
                                        "print(\"生成多样性评估:\")\n",
                                        "print(\"=\" * 50)\n",
                                        "\n",
                                        "diversity_results = {}\n",
                                        "\n",
                                        "DIVERSITY_PROMPTS = [t[\"instruction\"] for t in TEST_TASKS[:MAX_DIVERSITY_PROMPTS]]\n",
                                        "\n",
                                        "for name, model in models.items():\n",
                                        "    responses = []\n",
                                        "    use_chatml = 'Base' not in name\n",
                                        "\n",
                                        "    for prompt in DIVERSITY_PROMPTS:\n",
                                        "        for _ in range(DIVERSITY_SAMPLES_PER_PROMPT):\n",
                                        "            response = generate_response(\n",
                                        "                model, tokenizer, prompt,\n",
                                        "                temperature=0.8,\n",
                                        "                use_chatml=use_chatml,\n",
                                        "                do_sample=True\n",
                                        "            )\n",
                                        "            responses.append(response)\n",
                                        "\n",
                                        "    distinct_1, distinct_2 = compute_diversity(responses)\n",
                                        "    diversity_results[name] = (distinct_1, distinct_2)\n",
                                        "\n",
                                        "    print(f\"\\n{name}:\")\n",
                                        "    print(f\"  Distinct-1 (字符级): {distinct_1:.4f}\")\n",
                                        "    print(f\"  Distinct-2 (bigram): {distinct_2:.4f}\")\n",
                                        "    print(f\"  平均回答长度: {np.mean([len(r) for r in responses]):.1f}字符\")\n"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "## Part 5: 偏好一致性评估"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "# 偏好测试数据（结构化“要点”风格偏好）\n",
                                        "print(f\"偏好测试对数: {len(PREFERENCE_TEST)}\")\n"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "@torch.no_grad()\n",
                                        "def compute_response_prob(model, tokenizer, prompt, response):\n",
                                        "    \"\"\"\n",
                                        "    计算给定prompt下response的对数概率\n",
                                        "    \"\"\"\n",
                                        "    model.eval()\n",
                                        "    \n",
                                        "    # 使用ChatML格式\n",
                                        "    full_text = ChatMLFormatter.format_prompt_only(prompt) + response + ChatMLFormatter.END_TOKEN\n",
                                        "    prompt_text = ChatMLFormatter.format_prompt_only(prompt)\n",
                                        "    \n",
                                        "    full_ids = tokenizer.encode(full_text, add_bos=True, add_eos=False)\n",
                                        "    prompt_ids = tokenizer.encode(prompt_text, add_bos=True, add_eos=False)\n",
                                        "    \n",
                                        "    response_start = len(prompt_ids)\n",
                                        "    \n",
                                        "    input_ids = torch.tensor([full_ids[:-1]]).to(device)\n",
                                        "    labels = torch.tensor([full_ids[1:]]).to(device)\n",
                                        "    \n",
                                        "    outputs = model(input_ids)\n",
                                        "    logits = outputs['logits']\n",
                                        "    \n",
                                        "    log_probs = F.log_softmax(logits, dim=-1)\n",
                                        "    per_token_log_probs = torch.gather(log_probs, dim=-1, index=labels.unsqueeze(-1)).squeeze(-1)\n",
                                        "    \n",
                                        "    # 只计算response部分\n",
                                        "    response_log_prob = per_token_log_probs[0, response_start-1:].sum().item()\n",
                                        "    \n",
                                        "    return response_log_prob"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "# 评估偏好一致性\n",
                                        "print(\"偏好一致性评估:\")\n",
                                        "print(\"=\" * 60)\n",
                                        "print(\"(模型是否更倾向于chosen回答而非rejected回答)\")\n",
                                        "\n",
                                        "preference_results = {name: [] for name in models.keys()}\n",
                                        "\n",
                                        "for item in PREFERENCE_TEST:\n",
                                        "    for name, model in models.items():\n",
                                        "        chosen_prob = compute_response_prob(model, tokenizer, item['prompt'], item['chosen'])\n",
                                        "        rejected_prob = compute_response_prob(model, tokenizer, item['prompt'], item['rejected'])\n",
                                        "\n",
                                        "        prefers_chosen = chosen_prob > rejected_prob\n",
                                        "        preference_results[name].append(prefers_chosen)\n",
                                        "\n",
                                        "        symbol = \"OK\" if prefers_chosen else \"NO\"\n",
                                        "print(\"\\n\" + \"=\" * 60)\n",
                                        "print(\"\\n偏好一致性总结:\")\n",
                                        "for name, results in preference_results.items():\n",
                                        "    accuracy = sum(results) / len(results) * 100\n",
                                        "    print(f\"  {name}: {accuracy:.1f}% ({sum(results)}/{len(results)})\")\n"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "## Part 6: 综合评估报告"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "# 创建综合评估表格\n",
                                        "print(\"\\n\" + \"=\" * 80)\n",
                                        "print(\"                       综合评估报告\")\n",
                                        "print(\"=\" * 80)\n",
                                        "\n",
                                        "# 准备数据\n",
                                        "metrics = []\n",
                                        "report_data = []\n",
                                        "\n",
                                        "for name in models.keys():\n",
                                        "    ppl = ppl_results.get(name)\n",
                                        "    instr = instruction_results.get(name, {}).get('overall') if name in instruction_results else None\n",
                                        "    distinct_1, distinct_2 = diversity_results.get(name, (None, None)) if name in diversity_results else (None, None)\n",
                                        "    pref = sum(preference_results[name]) / len(preference_results[name]) if name in preference_results else None\n",
                                        "    diversity_avg = None if distinct_1 is None or distinct_2 is None else (distinct_1 + distinct_2) / 2\n",
                                        "\n",
                                        "    metrics.append({\n",
                                        "        'model': name,\n",
                                        "        'ppl': ppl,\n",
                                        "        'instr': instr,\n",
                                        "        'pref': pref,\n",
                                        "        'distinct_1': distinct_1,\n",
                                        "        'distinct_2': distinct_2,\n",
                                        "        'diversity_avg': diversity_avg\n",
                                        "    })\n",
                                        "\n",
                                        "def normalize(values, higher_better=True):\n",
                                        "    vals = [v for v in values if v is not None]\n",
                                        "    if not vals:\n",
                                        "        return [None for _ in values]\n",
                                        "    vmin, vmax = min(vals), max(vals)\n",
                                        "    if vmax == vmin:\n",
                                        "        return [1.0 if v is not None else None for v in values]\n",
                                        "    normed = []\n",
                                        "    for v in values:\n",
                                        "        if v is None:\n",
                                        "            normed.append(None)\n",
                                        "            continue\n",
                                        "        n = (v - vmin) / (vmax - vmin)\n",
                                        "        normed.append(n if higher_better else 1 - n)\n",
                                        "    return normed\n",
                                        "\n",
                                        "ppl_vals = [m['ppl'] for m in metrics]\n",
                                        "instr_vals = [m['instr'] for m in metrics]\n",
                                        "pref_vals = [m['pref'] for m in metrics]\n",
                                        "div_vals = [m['diversity_avg'] for m in metrics]\n",
                                        "\n",
                                        "ppl_norm = normalize(ppl_vals, higher_better=False)\n",
                                        "instr_norm = normalize(instr_vals, higher_better=True)\n",
                                        "pref_norm = normalize(pref_vals, higher_better=True)\n",
                                        "div_norm = normalize(div_vals, higher_better=True)\n",
                                        "\n",
                                        "for i, m in enumerate(metrics):\n",
                                        "    weights = {'instr': 0.35, 'pref': 0.35, 'div': 0.2, 'ppl': 0.1}\n",
                                        "    score = 0.0\n",
                                        "    total = 0.0\n",
                                        "    if instr_norm[i] is not None:\n",
                                        "        score += weights['instr'] * instr_norm[i]\n",
                                        "        total += weights['instr']\n",
                                        "    if pref_norm[i] is not None:\n",
                                        "        score += weights['pref'] * pref_norm[i]\n",
                                        "        total += weights['pref']\n",
                                        "    if div_norm[i] is not None:\n",
                                        "        score += weights['div'] * div_norm[i]\n",
                                        "        total += weights['div']\n",
                                        "    if ppl_norm[i] is not None:\n",
                                        "        score += weights['ppl'] * ppl_norm[i]\n",
                                        "        total += weights['ppl']\n",
                                        "    overall = score / total if total > 0 else None\n",
                                        "    m['overall'] = overall\n",
                                        "\n",
                                        "    report_data.append({\n",
                                        "        '模型': m['model'],\n",
                                        "        '综合得分': m['overall'],\n",
                                        "        '指令准确率': m['instr'],\n",
                                        "        '偏好一致性': m['pref'],\n",
                                        "        'Distinct-1': m['distinct_1'],\n",
                                        "        'Distinct-2': m['distinct_2'],\n",
                                        "        '困惑度': m['ppl']\n",
                                        "    })\n",
                                        "\n",
                                        "# 打印表格\n",
                                        "df = pd.DataFrame(report_data)\n",
                                        "df = df.sort_values(by='综合得分', ascending=False, na_position='last')\n",
                                        "display_df = df.copy()\n",
                                        "display_df['综合得分'] = display_df['综合得分'].map(lambda x: f\"{x:.3f}\" if pd.notna(x) else 'N/A')\n",
                                        "display_df['指令准确率'] = display_df['指令准确率'].map(lambda x: f\"{x*100:.1f}%\" if pd.notna(x) else 'N/A')\n",
                                        "display_df['偏好一致性'] = display_df['偏好一致性'].map(lambda x: f\"{x*100:.1f}%\" if pd.notna(x) else 'N/A')\n",
                                        "display_df['Distinct-1'] = display_df['Distinct-1'].map(lambda x: f\"{x:.4f}\" if pd.notna(x) else 'N/A')\n",
                                        "display_df['Distinct-2'] = display_df['Distinct-2'].map(lambda x: f\"{x:.4f}\" if pd.notna(x) else 'N/A')\n",
                                        "display_df['困惑度'] = display_df['困惑度'].map(lambda x: f\"{x:.2f}\" if pd.notna(x) else 'N/A')\n",
                                        "display_df = display_df[['模型', '综合得分', '指令准确率', '偏好一致性', 'Distinct-1', 'Distinct-2', '困惑度']]\n",
                                        "print(display_df.to_string(index=False, col_space=12))\n",
                                        "\n",
                                        "# 评估说明\n",
                                        "print(\"\\n评估说明:\")\n",
                                        "print(f\"- 指令准确率: 文本软匹配(F1/LCS/BigramRecall), 阈值={TEXT_SIM_THRESHOLD:.2f}\")\n",
                                        "print(\"- 困惑度: 越低越好; DPO可能上升\")\n",
                                        "print(\"- Distinct-1: 字符级多样性, Distinct-2: Bigram多样性 (越高越好)\")\n",
                                        "print(\"- 偏好一致性: 越高越好\")\n",
                                        "\n",
                                        "# 亮点汇总\n",
                                        "def pick_best(metric_key, higher_better=True):\n",
                                        "    items = [m for m in metrics if m.get(metric_key) is not None]\n",
                                        "    if not items:\n",
                                        "        return None\n",
                                        "    key_fn = (lambda x: x[metric_key])\n",
                                        "    best = max(items, key=key_fn) if higher_better else min(items, key=key_fn)\n",
                                        "    return best\n",
                                        "\n",
                                        "print(\"\\n亮点汇总:\")\n",
                                        "best_ppl = pick_best('ppl', higher_better=False)\n",
                                        "best_instr = pick_best('instr', higher_better=True)\n",
                                        "best_pref = pick_best('pref', higher_better=True)\n",
                                        "best_div = pick_best('diversity_avg', higher_better=True)\n",
                                        "best_overall = pick_best('overall', higher_better=True)\n",
                                        "\n",
                                        "if best_ppl:\n",
                                        "    print(f\"- 困惑度最低: {best_ppl['model']} ({best_ppl['ppl']:.2f})\")\n",
                                        "if best_instr:\n",
                                        "    print(f\"- 指令最准: {best_instr['model']} ({best_instr['instr']*100:.1f}%)\")\n",
                                        "if best_pref:\n",
                                        "    print(f\"- 偏好一致性最高: {best_pref['model']} ({best_pref['pref']*100:.1f}%)\")\n",
                                        "if best_div:\n",
                                        "    print(f\"- 多样性最高: {best_div['model']} ({best_div['diversity_avg']:.4f})\")\n",
                                        "if best_overall:\n",
                                        "    print(f\"- 综合得分最高: {best_overall['model']} ({best_overall['overall']:.3f})\")\n"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "# 可视化综合对比\n",
                                        "fig, axes = plt.subplots(3, 2, figsize=(14, 14))\n",
                                        "\n",
                                        "model_names = list(models.keys())\n",
                                        "colors = ['#3498db', '#2ecc71', '#9b59b6']\n",
                                        "\n",
                                        "# 1. 困惑度\n",
                                        "ax = axes[0, 0]\n",
                                        "ppl_names = [name for name in model_names if name in ppl_results]\n",
                                        "values = [ppl_results[name] for name in ppl_names]\n",
                                        "bars = ax.bar(ppl_names, values, color=colors[:len(ppl_names)])\n",
                                        "for bar, val in zip(bars, values):\n",
                                        "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
                                        "            f'{val:.1f}', ha='center', va='bottom', fontsize=10)\n",
                                        "ax.set_ylabel('困惑度')\n",
                                        "ax.set_title('困惑度对比 (含DPO, 越低越好)', fontweight='bold')\n",
                                        "ax.grid(True, alpha=0.3, axis='y')\n",
                                        "\n",
                                        "# 2. 指令准确率\n",
                                        "ax = axes[0, 1]\n",
                                        "values = [instruction_results.get(name, {}).get('overall', 0)*100 for name in model_names]\n",
                                        "bars = ax.bar(model_names, values, color=colors[:len(model_names)])\n",
                                        "for bar, val in zip(bars, values):\n",
                                        "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
                                        "            f'{val:.1f}%', ha='center', va='bottom', fontsize=10)\n",
                                        "ax.set_ylabel('准确率 (%)')\n",
                                        "ax.set_title('指令准确率 (越高越好)', fontweight='bold')\n",
                                        "ax.set_ylim(0, 110)\n",
                                        "ax.grid(True, alpha=0.3, axis='y')\n",
                                        "\n",
                                        "# 3. Distinct-1\n",
                                        "ax = axes[1, 0]\n",
                                        "values = [diversity_results.get(name, (0,0))[0] for name in model_names]\n",
                                        "bars = ax.bar(model_names, values, color=colors[:len(model_names)])\n",
                                        "for bar, val in zip(bars, values):\n",
                                        "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
                                        "            f'{val:.3f}', ha='center', va='bottom', fontsize=10)\n",
                                        "ax.set_ylabel('Distinct-1')\n",
                                        "ax.set_title('字符级多样性 (越高越好)', fontweight='bold')\n",
                                        "ax.grid(True, alpha=0.3, axis='y')\n",
                                        "\n",
                                        "# 4. Distinct-2\n",
                                        "ax = axes[1, 1]\n",
                                        "values = [diversity_results.get(name, (0,0))[1] for name in model_names]\n",
                                        "bars = ax.bar(model_names, values, color=colors[:len(model_names)])\n",
                                        "for bar, val in zip(bars, values):\n",
                                        "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
                                        "            f'{val:.3f}', ha='center', va='bottom', fontsize=10)\n",
                                        "ax.set_ylabel('Distinct-2')\n",
                                        "ax.set_title('Bigram多样性 (越高越好)', fontweight='bold')\n",
                                        "ax.grid(True, alpha=0.3, axis='y')\n",
                                        "\n",
                                        "# 5. 偏好一致性\n",
                                        "ax = axes[2, 0]\n",
                                        "values = [sum(preference_results[name])/len(preference_results[name])*100 \n",
                                        "          if name in preference_results else 0 for name in model_names]\n",
                                        "bars = ax.bar(model_names, values, color=colors[:len(model_names)])\n",
                                        "for bar, val in zip(bars, values):\n",
                                        "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
                                        "            f'{val:.1f}%', ha='center', va='bottom', fontsize=10)\n",
                                        "ax.set_ylabel('一致性 (%)')\n",
                                        "ax.set_title('偏好一致性 (越高越好)', fontweight='bold')\n",
                                        "ax.set_ylim(0, 110)\n",
                                        "ax.axhline(y=50, color='red', linestyle='--', alpha=0.5, label='随机基线')\n",
                                        "ax.legend()\n",
                                        "ax.grid(True, alpha=0.3, axis='y')\n",
                                        "\n",
                                        "# 6. 综合得分\n",
                                        "ax = axes[2, 1]\n",
                                        "score_map = df.set_index('模型')['综合得分'].to_dict() if '综合得分' in df.columns else {}\n",
                                        "values = [score_map.get(name, 0) for name in model_names]\n",
                                        "bars = ax.bar(model_names, values, color=colors[:len(model_names)])\n",
                                        "for bar, val in zip(bars, values):\n",
                                        "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
                                        "            f'{val:.3f}', ha='center', va='bottom', fontsize=10)\n",
                                        "ax.set_ylabel('综合得分')\n",
                                        "ax.set_title('综合得分 (加权归一化)', fontweight='bold')\n",
                                        "ax.set_ylim(0, 1.05)\n",
                                        "ax.grid(True, alpha=0.3, axis='y')\n",
                                        "\n",
                                        "plt.tight_layout()\n",
                                        "plt.savefig(os.path.join(CHECKPOINT_DIR, 'evaluation_results.png'), dpi=150, bbox_inches='tight')\n",
                                        "plt.show()\n",
                                        "\n",
                                        "print(f\"\\n评估结果已保存至: {CHECKPOINT_DIR}/evaluation_results.png\")"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "## Part 7: 训练流程总结"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "# 训练流程图\n",
                                        "fig, ax = plt.subplots(figsize=(14, 6))\n",
                                        "ax.set_xlim(0, 14)\n",
                                        "ax.set_ylim(0, 8)\n",
                                        "ax.axis('off')\n",
                                        "ax.set_title('自建GPT完整训练流程', fontsize=16, fontweight='bold', pad=20)\n",
                                        "\n",
                                        "# 颜色\n",
                                        "colors = {\n",
                                        "    'pretrain': '#3498db',\n",
                                        "    'sft': '#2ecc71',\n",
                                        "    'dpo': '#9b59b6',\n",
                                        "    'eval': '#e74c3c'\n",
                                        "}\n",
                                        "\n",
                                        "# 阶段框\n",
                                        "stages = [\n",
                                        "    (1, 5, '01\\n模型组装', '构建模型\\n定义架构', '#95a5a6'),\n",
                                        "    (3.5, 5, '02\\n预训练', 'Next-token\\nPrediction', colors['pretrain']),\n",
                                        "    (6, 5, '03\\nSFT', '指令微调\\nLoss Masking', colors['sft']),\n",
                                        "    (8.5, 5, '04\\nDPO', '偏好对齐\\nPreference', colors['dpo']),\n",
                                        "    (11, 5, '05\\n评估', '困惑度\\n多样性', colors['eval']),\n",
                                        "]\n",
                                        "\n",
                                        "for x, y, title, desc, color in stages:\n",
                                        "    # 框\n",
                                        "    rect = plt.Rectangle((x, y-1), 2, 2.5, color=color, ec='black', linewidth=2, alpha=0.8)\n",
                                        "    ax.add_patch(rect)\n",
                                        "    # 标题\n",
                                        "    ax.text(x+1, y+1.2, title, ha='center', va='center', fontsize=11, fontweight='bold', color='white')\n",
                                        "    # 描述\n",
                                        "    ax.text(x+1, y-0.3, desc, ha='center', va='center', fontsize=9, color='white')\n",
                                        "\n",
                                        "# 箭头\n",
                                        "arrow_style = dict(arrowstyle='->', color='black', lw=2)\n",
                                        "for i in range(4):\n",
                                        "    ax.annotate('', xy=(stages[i+1][0], 5), xytext=(stages[i][0]+2, 5),\n",
                                        "                arrowprops=arrow_style)\n",
                                        "\n",
                                        "# 模型输出\n",
                                        "outputs = [\n",
                                        "    (2, 2, 'CustomGPT\\n(~12.6M参数)'),\n",
                                        "    (4.5, 2, 'Base模型\\n(会说话)'),\n",
                                        "    (7, 2, 'SFT模型\\n(会听话)'),\n",
                                        "    (9.5, 2, 'DPO模型\\n(会选择)'),\n",
                                        "    (12, 2, '评估报告'),\n",
                                        "]\n",
                                        "\n",
                                        "for x, y, text in outputs:\n",
                                        "    ax.annotate(text, xy=(x, y), ha='center', va='center', fontsize=9,\n",
                                        "                bbox=dict(boxstyle='round,pad=0.3', facecolor='lightyellow', edgecolor='black'))\n",
                                        "    ax.annotate('', xy=(x, 2.7), xytext=(x, 4),\n",
                                        "                arrowprops=dict(arrowstyle='->', color='gray', lw=1, ls='--'))\n",
                                        "\n",
                                        "plt.tight_layout()\n",
                                        "plt.show()"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "## 总结\n",
                                        "\n",
                                        "### 完整训练流程回顾\n",
                                        "\n",
                                        "```\n",
                                        "01_Model_Assembly.ipynb\n",
                                        "├── 构建CustomGPT模型 (~12.6M参数)\n",
                                        "├── RoPE位置编码 + RMSNorm + SwiGLU\n",
                                        "└── 输出: 随机初始化的模型\n",
                                        "\n",
                                        "02_Pretraining.ipynb\n",
                                        "├── Next-token Prediction任务\n",
                                        "├── 学习语言的统计规律\n",
                                        "└── 输出: Base模型（会\"说话\"）\n",
                                        "\n",
                                        "03_SFT_Training.ipynb\n",
                                        "├── ChatML格式的指令数据\n",
                                        "├── Loss Masking（只对回答计算loss）\n",
                                        "└── 输出: SFT模型（会\"听话\"）\n",
                                        "\n",
                                        "04_DPO_Training.ipynb\n",
                                        "├── (chosen, rejected)偏好对数据\n",
                                        "├── 直接优化偏好概率差异\n",
                                        "└── 输出: DPO模型（会\"选择\"）\n",
                                        "\n",
                                        "05_Evaluation.ipynb (本notebook)\n",
                                        "├── 困惑度评估\n",
                                        "├── 指令遵循能力\n",
                                        "├── 生成多样性\n",
                                        "└── 偏好一致性\n",
                                        "```\n",
                                        "\n",
                                        "### 各阶段模型特点\n",
                                        "\n",
                                        "| 模型 | 能力 | 特点 |\n",
                                        "|------|------|------|\n",
                                        "| Base | 文本续写 | 理解语言规律，但不懂指令 |\n",
                                        "| SFT | 指令遵循 | 理解用户意图，生成相关回答 |\n",
                                        "| DPO | 偏好对齐 | 倾向生成人类偏好的回答 |\n",
                                        "\n",
                                        "### 关键技术点\n",
                                        "\n",
                                        "1. **小模型优势**: ~12.6M参数，CPU可训练，适合学习和实验\n",
                                        "2. **Loss Masking**: SFT中只对assistant部分计算loss\n",
                                        "3. **DPO算法**: 无需Reward Model，直接从偏好数据学习\n",
                                        "4. **完整pipeline**: 从零到可用的完整训练流程\n",
                                        "\n",
                                        "### 与HuggingFace GPT-2训练的对比\n",
                                        "\n",
                                        "| 维度 | 自建GPT | HuggingFace GPT-2 |\n",
                                        "|------|---------|-------------------|\n",
                                        "| 参数量 | ~12.6M | 124M+ |\n",
                                        "| 训练设备 | CPU/GPU | 需要GPU |\n",
                                        "| 透明度 | 完全透明 | 部分黑盒 |\n",
                                        "| 定制性 | 高 | 中 |\n",
                                        "| 性能 | 学习/演示用 | 生产可用 |\n",
                                        "\n",
                                        "恭喜完成本教程包含的:\n",
                                        "- 学习LLM训练原理\n",
                                        "- 快速实验新想法\n",
                                        "- 资源受限场景\n",
                                        "- 教学演示"
                              ]
                    }
          ],
          "metadata": {
                    "kernelspec": {
                              "display_name": "llmc",
                              "language": "python",
                              "name": "python3"
                    },
                    "language_info": {
                              "codemirror_mode": {
                                        "name": "ipython",
                                        "version": 3
                              },
                              "file_extension": ".py",
                              "mimetype": "text/x-python",
                              "name": "python",
                              "nbconvert_exporter": "python",
                              "pygments_lexer": "ipython3",
                              "version": "3.9.25"
                    }
          },
          "nbformat": 4,
          "nbformat_minor": 4
}
